import streamlit as st
import google.generativeai as genai
import os

# --- Page Setup and Title ---
st.set_page_config(page_title="á‹¨áŒá‰¥áˆ­áŠ“ áŠ áˆ›áŠ«áˆª á‰»á‰µá‰¦á‰µ", layout="centered", initial_sidebar_state="collapsed")
st.title("ğŸ¤– á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŠ áˆ›áŠ«áˆª (AI Chatbot)")
st.caption("á‰ áŠ áˆ›áˆ­áŠ› áˆµáˆˆ áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŒ‰á‹³á‹®á‰½ á‹­áŒ á‹­á‰") # Ask about agriculture and food issues in Amharic

# --- Gemini API Key Configuration ---
# 1. From Streamlit Secrets (for deployment)
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")

# 2. From Environment Variable (for local development)
if not GEMINI_API_KEY:
    GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# 3. User input (for demo/quick testing - not recommended for production)
if not GEMINI_API_KEY:
    st.sidebar.subheader("á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆá") # Gemini API Key
    GEMINI_API_KEY_INPUT = st.sidebar.text_input("áŠ¤á’áŠ á‹­ á‰áˆáá‹áŠ• áŠ¥á‹šáˆ… á‹«áˆµáŒˆá‰¡á¦", type="password", key="api_key_input_chat") # Enter your API key here:
    if GEMINI_API_KEY_INPUT:
        GEMINI_API_KEY = GEMINI_API_KEY_INPUT
    else:
        st.warning("âš ï¸ á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆá áŠ áˆá‰°áŒˆáŠ˜áˆá¢ áŠ¥á‰£áŠ­á‹ á‰ áŒáŠ• áŠ áˆáˆŒá‹ áˆ‹á‹­ á‹«áˆµáŒˆá‰¡ á‹ˆá‹­áˆ á‰  Streamlit Secrets/Environment Variables á‹«á‹˜áŒ‹áŒá¢") # Gemini API key not found. Please enter it in the sidebar or set it up in Streamlit Secrets/Environment Variables.
        st.stop() # Stop the app if no key

try:
    genai.configure(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆááŠ• á‰ áˆ›á‹‹á‰€áˆ­ áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}") # Error configuring Gemini API key: {e}
    st.stop()

# --- Selecting and Configuring Gemini Model ---
# Use models better suited for conversation (e.g., 'gemini-1.5-flash' or 'gemini-pro')
MODEL_NAME = "gemini-1.5-flash" # or 'gemini-pro'

# System Prompt (in Amharic)
SYSTEM_PROMPT_AMHARIC = """áˆ°áˆ‹áˆ! áŠ¥áŠ” áˆµáˆˆ áŠ¢á‰µá‹®áŒµá‹« áŒá‰¥áˆ­áŠ“á£ áŠ á‹áˆ˜áˆ« áŠ áˆ˜áˆ«áˆ¨á‰µá£ á‹¨áŠ¥áŠ•áˆµáˆ³á‰µ áŠ¥áˆ­á‰£á‰³ á‹˜á‹´á‹á‰½ã€ á‹¨áŠ áˆáˆ­áŠ“ á‹áˆƒ áŠ á‹«á‹«á‹ã€ á‹¨áˆ°á‰¥áˆ á‰°á‰£á‹­áŠ“ á‰ áˆ½á‰³ á‰áŒ¥áŒ¥áˆ­ã€ á‹˜áˆ˜áŠ“á‹Š á‹¨áŒá‰¥áˆ­áŠ“ á‰´áŠ­áŠ–áˆáŒ‚á‹á‰½ã€ á‹¨áˆáŒá‰¥ áŠ á‹­áŠá‰¶á‰½ã€ á‹¨áˆáŒá‰¥ á‹áŒáŒ…á‰µã€ á‹¨áˆáŒá‰¥ á‹°áˆ…áŠ•áŠá‰µã€ áŠ¥áŠ“ áˆµáŠ-áˆáŒá‰¥ áŒ‰á‹³á‹®á‰½ áˆ˜áˆ¨áŒƒ áˆˆáˆ˜áˆµáŒ á‰µáŠ“ áˆˆáˆ˜á‹ˆá‹«á‹¨á‰µ á‹¨á‰°á‹˜áŒ‹áŒ€áˆ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ á‹¨áˆ›áˆ°á‰¥ á‰½áˆá‰³ áˆ¨á‹³á‰µ áŠáŠá¢ áŠ¥á‰£áŠ­á‹áŠ• áŒ¥á‹«á‰„á‹áŠ• á‰ áŠ¥áŠá‹šáˆ… áˆ­á‹•áˆ¶á‰½ á‹™áˆªá‹« á‰¥á‰» á‹«á‰…áˆ­á‰¡á¢ áŠ¨áŠ¥áŠá‹šáˆ… áˆ­á‹•áˆ¶á‰½ á‹áŒª áˆˆáˆšá‰€áˆ­á‰¡ áŒ¥á‹«á‰„á‹á‰½ áˆ˜áˆáˆµ áˆˆáˆ˜áˆµáŒ á‰µáˆ áˆ†áŠ áˆˆáˆ˜á‹ˆá‹«á‹¨á‰µ áŠ áˆá‰°áˆá‰€á‹°áˆáŠáˆá¢ á‰ áŒá‰¥áˆ­áŠ“ á‹ˆá‹­áˆ á‰ áˆáŒá‰¥ áŠáŠ­ áŒ‰á‹³á‹­ áˆ‹á‹­ áˆáŠ• áˆáˆ­á‹³á‹á‰µ?"""
# Hello! I am an AI assistant designed to provide information and discuss Ethiopian agriculture, crop production, animal husbandry methods, soil and water management, crop pest and disease control, modern agricultural technologies, food types, food preparation, food safety, and nutrition issues. Please ask your questions only around these topics. I am not allowed to answer or discuss questions outside of these topics. What can I help you with regarding agriculture or food-related matters?

# Initialize the conversational model with the system prompt
try:
    model = genai.GenerativeModel(
        MODEL_NAME,
        system_instruction=SYSTEM_PROMPT_AMHARIC,
        # (Optional) Safety settings - may not be very necessary for agricultural content
        # safety_settings={
        #     'HATE': 'BLOCK_NONE',
        #     'HARASSMENT': 'BLOCK_NONE',
        #     'DANGEROUS' : 'BLOCK_NONE'
        # }
    )
    chat_session = model.start_chat(history=[]) # Start a chat session
except Exception as e:
    st.error(f"á‹¨ Gemini áˆá‹´áˆáŠ• á‰ áˆ›áˆµáŒ€áˆ˜áˆ­ áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}") # Error initializing Gemini model: {e}
    st.stop()


# --- Managing Chat History in Session State ---
if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = []
    # (Optional) Initial welcome message from the chatbot
    # st.session_state.chat_messages.append({"role": "model", "parts": [{"text": SYSTEM_PROMPT_AMHARIC.split("!")[0] + "! áˆáŠ• áˆáˆ­á‹³á‹á‰µ?"}]}) # What can I help you with?


# --- Displaying Chat Messages ---
for message in st.session_state.chat_messages:
    with st.chat_message(message["role"]):
        st.markdown(message["parts"][0]["text"])


# --- Receiving User Input ---
user_prompt = st.chat_input("áŒ¥á‹«á‰„á‹áŠ• áŠ¥á‹šáˆ… á‰ áŠ áˆ›áˆ­áŠ› á‹­áŒ»á‰...") # Write your question here in Amharic...

if user_prompt:
    # Add user's message to history and display it
    st.session_state.chat_messages.append({"role": "user", "parts": [{"text": user_prompt}]})
    with st.chat_message("user"):
        st.markdown(user_prompt)

    # Get and display response from Gemini
    with st.chat_message("model"):
        message_placeholder = st.empty()
        full_response_text = ""
        try:
            # Gemini API call - using chat history
            # For a direct chat session, use `send_message`
            response = chat_session.send_message(user_prompt, stream=True)

            for chunk in response:
                if hasattr(chunk, 'text') and chunk.text:
                    full_response_text += chunk.text
                    message_placeholder.markdown(full_response_text + "â–Œ") # To show "typing"
                elif hasattr(chunk, 'parts'): # Sometimes it might have 'parts'
                     for part in chunk.parts:
                         if hasattr(part, 'text') and part.text:
                            full_response_text += part.text
                            message_placeholder.markdown(full_response_text + "â–Œ")
            message_placeholder.markdown(full_response_text) # Display the final full response
        except Exception as e:
            full_response_text = f"á‹á‹­á‹­á‰±áŠ• á‰ áˆ›áˆµáŠ¬á‹µ áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}" # An error occurred while processing the chat: {e}
            message_placeholder.error(full_response_text)

    # Add model's response to history
    st.session_state.chat_messages.append({"role": "model", "parts": [{"text": full_response_text}]})

# (Optional) Button to clear chat history
if st.sidebar.button("á‹á‹­á‹­á‰±áŠ• áŠ áŒ½á‹³"): # Clear Chat
    st.session_state.chat_messages = []
    # chat_session = model.start_chat(history=[]) # A new chat session can be started
    st.rerun()

st.sidebar.markdown("---")
st.sidebar.info(f"á‹¨áˆšáŒ á‰€áˆ˜á‹ áˆá‹´áˆ: {MODEL_NAME}") 
