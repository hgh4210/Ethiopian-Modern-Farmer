import streamlit as st
import pandas as pd
import numpy as np
from PIL import Image
from io import BytesIO
import os
import joblib # For loading scikit-learn models
import datetime # For date operations

# Specific imports for each app (add all unique imports from all 6 projects here)
try:
    from inference_sdk import InferenceHTTPClient # For Injera App (Project 1)
except ImportError:
    # This will be handled within the injera app function if needed
    INFERENCE_SDK_AVAILABLE = False
else:
    INFERENCE_SDK_AVAILABLE = True

try:
    import google.generativeai as genai # For Chatbot (Project 5)
except ImportError:
    # This will be handled within the chatbot app function if needed
    GENAI_AVAILABLE = False
else:
    GENAI_AVAILABLE = True

# Scikit-learn imports (used by multiple apps)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, r2_score, mean_squared_error


# --- Global Page Configuration ---
st.set_page_config(
    page_title="áˆáˆ‰áŠ• áŠ á‰€á á‹¨áŒá‰¥áˆ­áŠ“ áˆµáˆ­á‹“á‰µ",
    page_icon="ğŸŒ½",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Helper function for constructing file paths relative to this main script ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def get_project_file_path(project_subfolder_name, filename):
    # If project_subfolder_name is empty, it means the file is in BASE_DIR (e.g. assets)
    if not project_subfolder_name:
        return os.path.join(BASE_DIR, filename)
    return os.path.join(BASE_DIR, project_subfolder_name, filename)

# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 1: á‹¨áŠ¥áŠ•áŒ€áˆ« áŒ¥áˆ«á‰µ áˆáˆ­áˆ˜áˆ«
# ==============================================================================
def run_injera_quality_app():
    st.header("ğŸ” á‹¨áŠ¥áŠ•áŒ€áˆ« áŒ¥áˆ«á‰µ áˆáˆ­áˆ˜áˆ«")
    st.markdown("á‹¨áŠ¥áŠ•áŒ€áˆ« áá‰¶ á‰ áˆ˜áˆµá‰€áˆ á‹ˆá‹­áˆ áŠ«áˆœáˆ« á‰ áˆ˜áŒ á‰€áˆ á‰ áˆ›áŠ•áˆ³á‰µ áŒ¥áˆ«á‰±áŠ• á‹­á‹ˆá‰á¢")

    if not INFERENCE_SDK_AVAILABLE:
        st.error("á‹¨ 'inference_sdk' á“áŠ¬áŒ… áŠ áˆá‰°áŒ«áŠáˆá¢ áŠ¥á‰£áŠ­á‹ á‹­áŒ«áŠ‘á‰µá¦ `pip install inference-sdk`")
        st.stop()

    ROBOFLOW_API_KEY_INJERA_ENV = os.environ.get("ROBOFLOW_API_KEY_INJERA")
    DEFAULT_API_KEY_INJERA = st.secrets.get("DEFAULT_ROBOFLOW_API_KEY_INJERA", "YOUR_DEFAULT_ROBOFLOW_KEY_HERE") # Example default, user should change
    DEFAULT_MODEL_ID_INJERA = "injera_quality/5" # User should verify/update this
    DEFAULT_API_URL_INJERA = "https://detect.roboflow.com" # Common URL, adjust if needed

    st.sidebar.subheader("á‹¨áŠ¥áŠ•áŒ€áˆ« áˆáˆ­áˆ˜áˆ« áˆ›á‹‹á‰€áˆªá‹«")
    api_key_injera = st.sidebar.text_input(
        "á‹¨áˆ®á‰¦ááˆá‹ áŠ¤á’áŠ á‹­ á‰áˆá (áˆˆáŠ¥áŠ•áŒ€áˆ«)",
        value=st.secrets.get("ROBOFLOW_API_KEY_INJERA", ROBOFLOW_API_KEY_INJERA_ENV or DEFAULT_API_KEY_INJERA),
        type="password", key="app1_injera_api_key"
    )
    model_id_injera = st.sidebar.text_input(
        "á‹¨áˆ®á‰¦ááˆá‹ áˆá‹´áˆ áˆ˜áˆˆá‹« (áˆˆáŠ¥áŠ•áŒ€áˆ«)", value=DEFAULT_MODEL_ID_INJERA, key="app1_injera_model_id"
    )
    api_url_injera = st.sidebar.text_input(
        "á‹¨áˆ®á‰¦ááˆá‹ áŠ¤á’áŠ á‹­ á‹©áŠ áˆ­áŠ¤áˆ (áˆˆáŠ¥áŠ•áŒ€áˆ«)", value=DEFAULT_API_URL_INJERA, key="app1_injera_api_url"
    )

    CLIENT_INJERA = None
    if api_key_injera and api_key_injera != "YOUR_DEFAULT_ROBOFLOW_KEY_HERE": # Avoid using placeholder key
        try:
            CLIENT_INJERA = InferenceHTTPClient(api_url=api_url_injera, api_key=api_key_injera)
        except Exception as e:
            st.sidebar.error(f"á‹¨áˆ®á‰¦ááˆá‹ á‹°áŠ•á‰ áŠ› (áŠ¥áŠ•áŒ€áˆ«) áˆˆáˆ˜áŒ€áˆ˜áˆ­ áŠ áˆá‰°á‰»áˆˆáˆ: {e}")
    elif api_key_injera == "YOUR_DEFAULT_ROBOFLOW_KEY_HERE":
        st.sidebar.warning("áŠ¥á‰£áŠ­á‹ á‰µáŠ­áŠ­áˆˆáŠ› á‹¨áˆ®á‰¦ááˆá‹ áŠ¤á’áŠ á‹­ á‰áˆá á‹«áˆµáŒˆá‰¡á¢")


    st.subheader("á‹¨áŠ¥áŠ•áŒ€áˆ« áˆáˆµáˆ á‹«á‰…áˆ­á‰¡")
    image_source_injera = st.radio(
        "á‹¨áˆáˆµáˆ áˆáŠ•áŒ­ á‹­áˆáˆ¨áŒ¡ (áŠ¥áŠ•áŒ€áˆ«)á¦", ("áˆáˆµáˆ á‹­áˆµá‰€áˆ‰", "á‰ áŠ«áˆœáˆ« áá‰¶ á‹«áŠ•áˆ±"),
        horizontal=True, key="app1_injera_img_source", label_visibility="collapsed"
    )

    img_bytes_for_processing_injera = None
    source_image_display_injera = None

    if image_source_injera == "áˆáˆµáˆ á‹­áˆµá‰€áˆ‰":
        img_file_buffer_injera = st.file_uploader(
            "á‹¨áŠ¥áŠ•áŒ€áˆ« áˆáˆµáˆá‹áŠ• á‹­áˆµá‰€áˆ‰ (JPG, PNG, JPEG)á¦", type=["jpg", "png", "jpeg"], key="app1_injera_uploader"
        )
        if img_file_buffer_injera:
            img_bytes_for_processing_injera = img_file_buffer_injera.getvalue()
            source_image_display_injera = Image.open(img_file_buffer_injera)
    elif image_source_injera == "á‰ áŠ«áˆœáˆ« áá‰¶ á‹«áŠ•áˆ±":
        camera_img_buffer_injera = st.camera_input("áá‰¶ áˆˆáˆ›áŠ•áˆ³á‰µ á‹­áŒ«áŠ‘ (áŠ¥áŠ•áŒ€áˆ«)á¦", key="app1_injera_camera")
        if camera_img_buffer_injera:
            img_bytes_for_processing_injera = camera_img_buffer_injera.getvalue()
            source_image_display_injera = Image.open(camera_img_buffer_injera)

    def translate_class_name_amharic_injera(class_name_en):
        translations = {"good": "áŒ¥áˆ©", "bad": "áˆ˜áŒ¥á", "fair": "áŠ¨áŠáˆ áŒ¥áˆ©"}
        return translations.get(class_name_en.lower(), class_name_en)

    if source_image_display_injera:
        col1_injera, col2_injera = st.columns(2)
        with col1_injera:
            st.image(source_image_display_injera, caption="á‹¨áŠ¥áˆ­áˆµá‹ á‹¨áŠ¥áŠ•áŒ€áˆ« áˆáˆµáˆ", use_column_width=True)
        with col2_injera:
            st.subheader("á‹¨áˆáˆ­áˆ˜áˆ« á‹áŒ¤á‰¶á‰½")
            if CLIENT_INJERA and img_bytes_for_processing_injera:
                if st.button("ğŸ”¬ á‹¨áŠ¥áŠ•áŒ€áˆ«áŠ• áŒ¥áˆ«á‰µ á‹­áˆ˜áˆ­áˆáˆ©", use_container_width=True, key="app1_injera_inspect_btn"):
                    with st.spinner("áŠ¥á‹¨á‰°áˆ˜áˆ¨áˆ˜áˆ¨ áŠá‹... áŠ¥á‰£áŠ­á‹ á‹­áŒ á‰¥á‰á¢"):
                        try:
                            pil_image_to_infer_injera = Image.open(BytesIO(img_bytes_for_processing_injera))
                            result_injera = CLIENT_INJERA.infer(pil_image_to_infer_injera, model_id=model_id_injera)
                            st.success("áˆáˆ­áˆ˜áˆ«á‹ á‰°áŒ áŠ“á‰‹áˆ!")
                            st.write("---")
                            if isinstance(result_injera, dict) and 'predictions' in result_injera: # Object detection
                                predictions_injera = result_injera.get('predictions', [])
                                if predictions_injera:
                                    st.write(f"**á‹¨á‰°áŒˆáŠ™ áŠáŒˆáˆ®á‰½/áŠ áŠ«á‰£á‰¢á‹á‰½ ({len(predictions_injera)})á¦**")
                                    for pred_injera in predictions_injera:
                                        pred_class_en_injera = pred_injera.get('class', "N/A")
                                        confidence_injera = pred_injera.get('confidence', 0)
                                        pred_class_am_injera = translate_class_name_amharic_injera(pred_class_en_injera)
                                        st.write(f"- **{pred_class_am_injera}** (á‹¨áˆ˜á‰°áˆ›áˆ˜áŠ• á‹°áˆ¨áŒƒá¦ {confidence_injera*100:.2f}%)")
                                        if pred_class_en_injera.lower() == "good": st.balloons()
                                else: st.write("á‰ á‹áŒ¤á‰± á‹áˆµáŒ¥ áˆáŠ•áˆ áŒáˆá‰¶á‰½ áŠ áˆá‰°áŒˆáŠ™áˆá¢")
                            # Handling for classification model structure (if top-level is list of dicts or dict with 'top' key)
                            elif isinstance(result_injera, dict) and 'top' in result_injera and 'confidence' in result_injera: # Classification
                                pred_class_en_injera = result_injera.get('top', "N/A")
                                confidence_injera = result_injera.get('confidence', 0)
                                pred_class_am_injera = translate_class_name_amharic_injera(pred_class_en_injera)
                                st.metric(
                                        label=f"á‹¨á‰°áŒˆáˆ˜á‰°á‹ áŒ¥áˆ«á‰µá¦ **{pred_class_am_injera}**",
                                        value=f"{confidence_injera*100:.2f}% á‹¨áˆ˜á‰°áˆ›áˆ˜áŠ• á‹°áˆ¨áŒƒ"
                                    )
                                if pred_class_en_injera.lower() == "good": st.balloons()
                                elif pred_class_en_injera.lower() == "bad": st.warning("á‹­áˆ… áŠ¥áŠ•áŒ€áˆ« á‹á‰…á‰°áŠ› áŒ¥áˆ«á‰µ á‹«áˆˆá‹ áˆŠáˆ†áŠ• á‹­á‰½áˆ‹áˆá¢")

                            elif isinstance(result_injera, list) and result_injera and 'class' in result_injera[0]: # Also can be object detection
                                st.write(f"**á‹¨á‰°áŒˆáŠ™ áŠáŒˆáˆ®á‰½/áŠ áŠ«á‰£á‰¢á‹á‰½ ({len(result_injera)})á¦**")
                                for pred_injera in result_injera:
                                    pred_class_en_injera = pred_injera.get('class', "N/A")
                                    confidence_injera = pred_injera.get('confidence', 0)
                                    pred_class_am_injera = translate_class_name_amharic_injera(pred_class_en_injera)
                                    st.write(f"- **{pred_class_am_injera}** (á‹¨áˆ˜á‰°áˆ›áˆ˜áŠ• á‹°áˆ¨áŒƒá¦ {confidence_injera*100:.2f}%)")
                            else:
                                st.info("áŒáˆá‰¶á‰½áŠ• áˆ˜á‰°áŠ•á‰°áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢ 'áŒ¥áˆ¬ á‹áŒ¤á‰µ' á‹­áˆ˜áˆáŠ¨á‰±á¢")
                            with st.expander("áŒ¥áˆ¬ á‹¨áˆ®á‰¦ááˆá‹ á‹áŒ¤á‰µ (áŠ¥áŠ•áŒáˆŠá‹áŠ›)", expanded=False):
                                st.json(result_injera)
                        except Exception as e_injera:
                            st.error(f"á‰ áŠ¢áŠ•áˆáˆ¨áŠ•áˆµ á‹ˆá‰…á‰µ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆ (áŠ¥áŠ•áŒ€áˆ«)á¦ {e_injera}")
            elif not CLIENT_INJERA:
                st.warning("á‹¨áˆ®á‰¦ááˆá‹ á‹°áŠ•á‰ áŠ› (áŠ¥áŠ•áŒ€áˆ«) áŠ áˆá‰°áŒ€áˆ˜áˆ¨áˆá¢ áˆ›á‹‹á‰€áˆªá‹«á‹áŠ• á‹«áˆ¨áŒ‹áŒáŒ¡á¢")
    else:
        st.info("áŠ¥á‰£áŠ­á‹ áˆáˆµáˆ á‹­áˆµá‰€áˆ‰ á‹ˆá‹­áˆ áá‰¶ á‹«áŠ•áˆ± (áˆˆáŠ¥áŠ•áŒ€áˆ«)á¢")
    st.markdown("--- \n á‰  [Roboflow](https://roboflow.com) á‹¨á‰°áŒáˆ‹á‰ á‰°")


# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 2: á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ á‰µáŠ•á‰ á‹«
# ==============================================================================
def run_milk_spoilage_app():
    st.header("ğŸ¥› á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ áŠ¥áŠ“ á‹¨áˆ˜á‰ áˆ‹áˆ¸á‰µ á‰µáŠ•á‰ á‹«")
    st.markdown("á‹¨á‹ˆá‰°á‰µá‹áŠ• áˆ˜áˆ¨áŒƒ á‰ áˆ›áˆµáŒˆá‰£á‰µ á‹¨áŒ¥áˆ«á‰µ á‹°áˆ¨áŒƒá‹áŠ• á‹­á‰°áŠ•á‰¥á‹©á¢")

    DATA_FILE_PATH_MILK = get_project_file_path("02_milk_spoilage_prediction", "milknew.csv")
    MODEL_FILE_PATH_MILK = get_project_file_path("02_milk_spoilage_prediction", "milk_quality_rf_model.joblib")
    SCALER_FILE_PATH_MILK = get_project_file_path("02_milk_spoilage_prediction", "milk_quality_scaler.joblib")

    @st.cache_data
    def load_and_preprocess_data_milk(file_path):
        try:
            df = pd.read_csv(file_path)
            df['Grade'] = df['Grade'].map({'high': 2, 'medium': 1, 'low': 0})
            if 'Fat ' in df.columns: df.rename(columns={'Fat ': 'Fat'}, inplace=True)
            # Handle potential missing values robustly
            for col in df.select_dtypes(include=np.number).columns:
                if df[col].isnull().any(): df[col].fillna(df[col].median(), inplace=True)
            for col in df.select_dtypes(include='object').columns: #Though 'Grade' is now numeric
                if df[col].isnull().any(): df[col].fillna(df[col].mode()[0], inplace=True)
            return df
        except FileNotFoundError:
            st.error(f"á‹¨á‹ˆá‰°á‰µ á‹³á‰³ á‹á‹­áˆ áŠ áˆá‰°áŒˆáŠ˜áˆá¦ {file_path}")
            return None
        except Exception as e:
            st.error(f"á‹¨á‹ˆá‰°á‰µ á‹³á‰³ á‰ áˆ˜áŒ«áŠ• áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}")
            return None

    df_milk = load_and_preprocess_data_milk(DATA_FILE_PATH_MILK)

    @st.cache_resource
    def train_or_load_model_and_scaler_milk(data_frame):
        if data_frame is None: return None, None
        
        # Ensure target 'Grade' is not in X_milk
        if 'Grade' not in data_frame.columns:
            st.error("á‹¨á‹’áˆ‹áˆ› á‹“áˆá‹µ 'Grade' á‰ á‹ˆá‰°á‰µ á‹³á‰³ á‹áˆµáŒ¥ á‹¨áˆˆáˆá¢")
            return None, None
            
        X_milk = data_frame.drop('Grade', axis=1, errors='ignore') # errors='ignore' if Grade was already removed
        y_milk = data_frame['Grade']

        # Verify X_milk columns (should be 7 features if Grade is target)
        expected_features = ['pH', 'Temprature', 'Taste', 'Odor', 'Fat', 'Turbidity', 'Colour']
        if not all(feat in X_milk.columns for feat in expected_features) or len(X_milk.columns) != len(expected_features):
            st.error(f"á‹¨á‹ˆá‰°á‰µ á‹³á‰³ áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ á‰µáŠ­áŠ­áˆ áŠ á‹­á‹°áˆ‰áˆá¢ á‹¨á‰°áŒ á‰ á‰á‰µ: {expected_features}, á‹¨á‰°áŒˆáŠ™á‰µ: {X_milk.columns.tolist()}")
            return None, None

        if os.path.exists(MODEL_FILE_PATH_MILK) and os.path.exists(SCALER_FILE_PATH_MILK):
            try:
                model = joblib.load(MODEL_FILE_PATH_MILK)
                scaler = joblib.load(SCALER_FILE_PATH_MILK)
                return model, scaler
            except Exception as e:
                st.sidebar.warning(f"á‹¨á‰°á‰€áˆ˜áŒ  á‹¨á‹ˆá‰°á‰µ áˆá‹´áˆ/áˆµáŠ¬áˆˆáˆ­ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆ ({e})á¢ áŠ á‹²áˆµ á‰ áˆ›áˆ°áˆáŒ áŠ• áˆ‹á‹­...")

        X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_milk, y_milk, test_size=0.2, random_state=42, stratify=y_milk)
        scaler_m = MinMaxScaler()
        X_train_scaled_m = scaler_m.fit_transform(X_train_m)
        X_test_scaled_m = scaler_m.transform(X_test_m)
        model_m = RandomForestClassifier(max_depth=12, random_state=0) # Example depth
        model_m.fit(X_train_scaled_m, y_train_m)
        accuracy_m = accuracy_score(y_test_m, model_m.predict(X_test_scaled_m))
        st.sidebar.metric(label="á‹¨á‹ˆá‰°á‰µ áˆá‹´áˆ á‰µáŠ­áŠ­áˆˆáŠ›áŠá‰µ (áŠ á‹²áˆµ á‹¨áˆ°áˆˆáŒ áŠ)", value=f"{accuracy_m*100:.2f}%", key="app2_milk_accuracy_retrained")
        try:
            joblib.dump(model_m, MODEL_FILE_PATH_MILK)
            joblib.dump(scaler_m, SCALER_FILE_PATH_MILK)
        except Exception as e_save: st.sidebar.error(f"á‹¨á‹ˆá‰°á‰µ áˆá‹´áˆ/áˆµáŠ¬áˆˆáˆ­ áˆ›áˆµá‰€áˆ˜áŒ¥ áŠ áˆá‰°á‰»áˆˆáˆá¦ {e_save}")
        return model_m, scaler_m

    if df_milk is None: st.stop()
    model_milk, scaler_milk = train_or_load_model_and_scaler_milk(df_milk)
    if not model_milk or not scaler_milk: st.error("á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ á‰µáŠ•á‰ á‹« áˆá‹´áˆ á‹ˆá‹­áˆ áˆµáŠ¬áˆˆáˆ­ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢"); st.stop()

    st.sidebar.subheader("á‹¨á‹ˆá‰°á‰µ áˆ˜áˆ¨áŒƒ á‹«áˆµáŒˆá‰¡")
    def user_input_features_milk(data_frame_for_ranges):
        # Use data_frame_for_ranges to get min/max for sliders to avoid errors if df_milk is None initially
        ph_m = st.sidebar.slider('á’áŠ¤á‰½ (pH)', float(data_frame_for_ranges['pH'].min()), float(data_frame_for_ranges['pH'].max()), float(data_frame_for_ranges['pH'].mean()), 0.1, key="app2_milk_ph")
        temp_m = st.sidebar.slider('á‹¨áˆ™á‰€á‰µ áˆ˜áŒ áŠ• (Â°C)', int(data_frame_for_ranges['Temprature'].min()), int(data_frame_for_ranges['Temprature'].max()), int(data_frame_for_ranges['Temprature'].mean()), key="app2_milk_temp")
        taste_m = st.sidebar.selectbox('áŒ£á‹•áˆ (0=áŠ­á‰, 1=áŒ¥áˆ©)', (0, 1), index=int(data_frame_for_ranges['Taste'].mode()[0]), key="app2_milk_taste")
        odor_m = st.sidebar.selectbox('áˆ½á‰³ (0=á‹¨áˆˆáˆ, 1=áŠ áˆˆ)', (0, 1), index=int(data_frame_for_ranges['Odor'].mode()[0]), key="app2_milk_odor")
        fat_m = st.sidebar.selectbox('á‹¨áˆµá‰¥ áˆ˜áŒ áŠ• (0=á‹á‰…á‰°áŠ›, 1=áŠ¨áá‰°áŠ›)', (0, 1), index=int(data_frame_for_ranges['Fat'].mode()[0]), key="app2_milk_fat")
        turb_m = st.sidebar.selectbox('á‹°á‰¥á‹›á‹áŠá‰µ (0=á‹¨áˆˆáˆ, 1=áŠ áˆˆ)', (0, 1), index=int(data_frame_for_ranges['Turbidity'].mode()[0]), key="app2_milk_turb")
        colour_m = st.sidebar.slider('á‰€áˆˆáˆ (áŠ¥áˆ´á‰µ)', int(data_frame_for_ranges['Colour'].min()), int(data_frame_for_ranges['Colour'].max()), int(data_frame_for_ranges['Colour'].mean()), key="app2_milk_colour")
        data = {'pH': ph_m, 'Temprature': temp_m, 'Taste': taste_m, 'Odor': odor_m, 'Fat': fat_m, 'Turbidity': turb_m, 'Colour': colour_m}
        return pd.DataFrame(data, index=[0])

    input_df_milk = user_input_features_milk(df_milk)
    st.subheader('áŠ¥áˆ­áˆµá‹ á‹«áˆµáŒˆá‰¡á‰µ á‹¨á‹ˆá‰°á‰µ áˆ˜áˆ¨áŒƒá¦')
    st.write(input_df_milk)

    if st.button("ğŸ¥› á‹¨á‹ˆá‰°á‰µáŠ• áŒ¥áˆ«á‰µ á‰°áŠ•á‰¥á‹­", key="app2_milk_predict_btn", use_container_width=True):
        input_df_scaled_milk = scaler_milk.transform(input_df_milk)
        prediction_milk = model_milk.predict(input_df_scaled_milk)
        prediction_proba_milk = model_milk.predict_proba(input_df_scaled_milk)
        st.subheader('á‹¨á‰µáŠ•á‰ á‹« á‹áŒ¤á‰µ (á‹ˆá‰°á‰µ)á¦')
        grade_map_amharic_milk = {2: "áŠ¨áá‰°áŠ› áŒ¥áˆ«á‰µ (High)", 1: "áˆ˜áŠ«áŠ¨áˆˆáŠ› áŒ¥áˆ«á‰µ (Medium)", 0: "á‹á‰…á‰°áŠ› áŒ¥áˆ«á‰µ (Low)"}
        predicted_grade_amharic_milk = grade_map_amharic_milk.get(prediction_milk[0], "á‹«áˆá‰³á‹ˆá‰€")
        st.success(f"á‹¨á‰°áŒˆáˆ˜á‰°á‹ á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ á‹°áˆ¨áŒƒá¦ **{predicted_grade_amharic_milk}**")
        if prediction_milk[0] == 0: st.warning("á‹­áˆ… á‹ˆá‰°á‰µ á‹á‰…á‰°áŠ› áŒ¥áˆ«á‰µ á‹«áˆˆá‹ á‹ˆá‹­áˆ á‹¨áˆ˜á‰ áˆ‹áˆ¸á‰µ áˆµáŒ‹á‰µ áˆŠáŠ–áˆ¨á‹ á‹­á‰½áˆ‹áˆá¢")
        elif prediction_milk[0] == 2: st.balloons()
        st.subheader('á‹¨áˆ˜á‰°áˆ›áˆ˜áŠ• á‹°áˆ¨áŒƒ áˆˆáŠ¥á‹«áŠ•á‹³áŠ•á‹± á‹¨áŒ¥áˆ«á‰µ áˆ˜á‹°á‰¥ (á‹ˆá‰°á‰µ)á¦')
        proba_df_milk = pd.DataFrame({
            "á‹¨áŒ¥áˆ«á‰µ áˆ˜á‹°á‰¥": [grade_map_amharic_milk[0], grade_map_amharic_milk[1], grade_map_amharic_milk[2]], # Order to match probabilities
            "á‹¨áˆ˜á‰°áˆ›áˆ˜áŠ• á‹•á‹µáˆ": [f"{p*100:.2f}%" for p in prediction_proba_milk[0]]
        })
        st.table(proba_df_milk)
# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 3: á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥
# ==============================================================================
def run_fertilizer_recommendation_app():
    st.header("ğŸŒ± á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥ áˆµáˆ­á‹“á‰µ")
    st.markdown("á‹¨áŠ áŠ«á‰£á‰¢á‹áŠ• áŠ¥áŠ“ á‹¨áˆ°á‰¥áˆá‹áŠ• áˆ˜áˆ¨áŒƒ á‰ áˆ›áˆµáŒˆá‰£á‰µ á‰°áˆµáˆ›áˆšá‹áŠ• áˆ›á‹³á‰ áˆªá‹« á‹­á‹ˆá‰á¢")

    # This should be the column name the *saved model expects*.
    # Based on the error, it's 'Temparature' (with 'a').
    MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME = 'Temparature'

    DATA_FILE_PATH_FERT = get_project_file_path("03_fertilizer_recommendation", "fertilizer_recommendation_data.csv")
    MODEL_PIPELINE_FILE_PATH_FERT = get_project_file_path("03_fertilizer_recommendation", "fertilizer_model_pipeline.joblib")
    TARGET_ENCODER_FILE_PATH_FERT = get_project_file_path("03_fertilizer_recommendation", "fertilizer_target_encoder.joblib")

    @st.cache_data
    def load_data_fert(file_path):
        try:
            df = pd.read_csv(file_path)
            df.columns = df.columns.str.strip()
            
            # Standardize temperature column name to what the model expects
            current_temp_col_in_csv = None
            if MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME in df.columns:
                current_temp_col_in_csv = MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME
            elif 'Temprature' in df.columns: # Check for 'e' spelling
                current_temp_col_in_csv = 'Temprature'
            elif 'Temperature' in df.columns: # Check for standard 'e' spelling (Temperature)
                current_temp_col_in_csv = 'Temperature'
            
            if current_temp_col_in_csv and current_temp_col_in_csv != MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME:
                #st.warning(f"á‹¨á‹“áˆá‹µ áˆµáˆ '{current_temp_col_in_csv}' á‹ˆá‹° '{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}' á‰°á‰€á‹­áˆ¯áˆ (áˆˆá‹ˆáŒ¥áŠá‰µ)á¢")
                df.rename(columns={current_temp_col_in_csv: MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}, inplace=True)
            elif not current_temp_col_in_csv:
                st.error(f"áˆµáˆ…á‰°á‰µá¦ á‰ á‹³á‰³ á‹á‹­áˆ‰ á‹áˆµáŒ¥ á‹ˆáˆ³áŠ á‹¨áˆ†áŠá‹ á‹¨áˆ™á‰€á‰µ áˆ˜áŒ áŠ• á‹“áˆá‹µ ('{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}', 'Temprature', or 'Temperature') áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
                return None

            if df.isnull().sum().any():
                for col in df.select_dtypes(include=np.number).columns: df[col].fillna(df[col].median(), inplace=True)
                for col in df.select_dtypes(include='object').columns: df[col].fillna(df[col].mode()[0], inplace=True)
            return df
        except FileNotFoundError: st.error(f"á‹¨áˆ›á‹³á‰ áˆªá‹« á‹³á‰³ á‹á‹­áˆ áŠ áˆá‰°áŒˆáŠ˜áˆá¦ {file_path}"); return None
        except Exception as e: st.error(f"á‹¨áˆ›á‹³á‰ áˆªá‹« á‹³á‰³ á‰ áˆ˜áŒ«áŠ• áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}"); return None

    df_fertilizer = load_data_fert(DATA_FILE_PATH_FERT)

    @st.cache_resource
    def train_or_load_model_pipeline_fert(data_frame):
        if data_frame is None: return None, None, None, None, None
        target_col_fert = 'Fertilizer Name'
        
        if MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME not in data_frame.columns:
            st.error(f"áˆµáˆ…á‰°á‰µá¦ '{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}' á‹“áˆá‹µ á‰ á‹³á‰³ ááˆ¬áˆ™ á‹áˆµáŒ¥ á‹¨áˆˆáˆ (áˆˆáˆá‹´áˆ áˆµáˆáŒ áŠ“)á¢")
            return None, None, None, None, None

        X_fert = data_frame.drop(target_col_fert, axis=1)
        y_raw_fert = data_frame[target_col_fert]
        target_encoder_fert = LabelEncoder()
        y_fert = target_encoder_fert.fit_transform(y_raw_fert)
        
        categorical_features_fert = ['Soil Type', 'Crop Type']
        numerical_features_fert = X_fert.select_dtypes(include=np.number).columns.tolist()
        
        if MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME not in numerical_features_fert:
            # This might happen if the column is object type, load_data_fert should prevent this.
            st.error(f"'{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}' á‹“áˆá‹µ áŠ¥áŠ•á‹° á‰áŒ¥áˆ­ áŠ áˆá‰°áŒˆáŠ˜áˆ (áˆˆáˆµáˆáŒ áŠ“)á¢ á‹¨á‹³á‰³ áŒ­áŠá‰µáŠ• á‹«áˆ¨áŒ‹áŒáŒ¡á¢")
            return None, None, None, None, None

        preprocessor_fert = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_features_fert),
                ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features_fert)],
            remainder='drop') # Changed to 'drop' for robustness
        
        model_pipeline_fert = Pipeline(steps=[
            ('preprocessor', preprocessor_fert),
            ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))])

        if os.path.exists(MODEL_PIPELINE_FILE_PATH_FERT) and os.path.exists(TARGET_ENCODER_FILE_PATH_FERT):
            try:
                loaded_pipeline = joblib.load(MODEL_PIPELINE_FILE_PATH_FERT)
                loaded_target_encoder = joblib.load(TARGET_ENCODER_FILE_PATH_FERT)
                return loaded_pipeline, loaded_target_encoder, data_frame['Soil Type'].unique(), data_frame['Crop Type'].unique(), data_frame
            except Exception as e: st.sidebar.warning(f"á‹¨á‰°á‰€áˆ˜áŒ  á‹¨áˆ›á‹³á‰ áˆªá‹« áˆá‹´áˆ/áŠ¢áŠ•áŠ®á‹°áˆ­ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆ ({e})á¢ áŠ á‹²áˆµ á‰ áˆ›áˆ°áˆáŒ áŠ• áˆ‹á‹­...")

        try:
            X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_fert, y_fert, test_size=0.2, random_state=42, stratify=y_fert)
            model_pipeline_fert.fit(X_train_f, y_train_f)
        except Exception as e_fit:
            st.error(f"á‹¨áˆ›á‹³á‰ áˆªá‹« áˆá‹´áˆáŠ• á‰ áˆ›áˆ°áˆáŒ áŠ• áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e_fit}")
            st.error(f"áˆˆáˆµáˆáŒ áŠ“ á‹¨á‰€áˆ¨á‰¡á‰µ á‹¨ X á‹“áˆá‹¶á‰½á¦ {X_fert.columns.tolist()}")
            return None, None, None, None, None

        accuracy_f = model_pipeline_fert.score(X_test_f, y_test_f)
        st.sidebar.metric(label="á‹¨áˆ›á‹³á‰ áˆªá‹« áˆá‹´áˆ á‰µáŠ­áŠ­áˆˆáŠ›áŠá‰µ (áŠ á‹²áˆµ á‹¨áˆ°áˆˆáŒ áŠ)", value=f"{accuracy_f*100:.2f}%", key="app3_fert_accuracy_retrained")
        try:
            joblib.dump(model_pipeline_fert, MODEL_PIPELINE_FILE_PATH_FERT)
            joblib.dump(target_encoder_fert, TARGET_ENCODER_FILE_PATH_FERT)
        except Exception as e_save: st.sidebar.error(f"á‹¨áˆ›á‹³á‰ áˆªá‹« áˆá‹´áˆ/áŠ¢áŠ•áŠ®á‹°áˆ­ áˆ›áˆµá‰€áˆ˜áŒ¥ áŠ áˆá‰°á‰»áˆˆáˆá¦ {e_save}")
        return model_pipeline_fert, target_encoder_fert, data_frame['Soil Type'].unique(), data_frame['Crop Type'].unique(), data_frame

    if df_fertilizer is None:
        st.error("á‹¨áˆ›á‹³á‰ áˆªá‹« á‹³á‰³ áˆ˜áŒ«áŠ• áˆµáˆ‹áˆá‰°á‰»áˆˆ á‹­áˆ… áˆ˜áˆ³áˆªá‹« áŠ á‹­áˆ°áˆ«áˆá¢")
        st.stop()
        
    pipeline_fert, LEncoder_fert, unique_soil_types_fert, unique_crop_types_fert, df_for_ranges_fert = train_or_load_model_pipeline_fert(df_fertilizer)
    
    if not pipeline_fert or not LEncoder_fert or df_for_ranges_fert is None :
        st.error("á‹¨áˆ›á‹³á‰ áˆªá‹« áˆá‹´áˆ á‹ˆá‹­áˆ áŠ áˆµáˆáˆ‹áŒŠ áˆ˜áˆ¨áŒƒá‹á‰½ áŠ áˆá‰°áŒ«áŠ‘áˆá¢")
        st.stop()

    st.sidebar.subheader("á‹¨áˆ›á‹³á‰ áˆªá‹« áˆ˜áˆ¨áŒƒ á‹«áˆµáŒˆá‰¡")
    def get_user_inputs_fert(soil_types_list, crop_types_list, data_for_input_ranges):
        user_inputs = {} # This dictionary will store inputs with correct keys
        
        # Temperature input: Use MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME for key and access
        if MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME not in data_for_input_ranges.columns:
            st.sidebar.error(f"áˆµáˆ…á‰°á‰µá¦ '{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}' á‹“áˆá‹µ á‰ á‹³á‰³á‹ (áˆˆá‹ˆáˆ°áŠ–á‰½) á‹áˆµáŒ¥ á‹¨áˆˆáˆá¢ áŠá‰£áˆª áŠ¥áˆ´á‰¶á‰½ áŒ¥á‰…áˆ áˆ‹á‹­ á‹­á‹áˆ‹áˆ‰á¢")
            temp_f_val = st.sidebar.slider(f'á‹¨áŠ á‹¨áˆ­ áˆ™á‰€á‰µ áˆ˜áŒ áŠ• (Â°C) [{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}]', 10, 40, 25, key="app3_fert_temp_main_fallback")
        else:
            temp_f_val = st.sidebar.slider(f'á‹¨áŠ á‹¨áˆ­ áˆ™á‰€á‰µ áˆ˜áŒ áŠ• (Â°C) [{MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME}]', 
                                            int(data_for_input_ranges[MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME].min()), 
                                            int(data_for_input_ranges[MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME].max()), 
                                            int(data_for_input_ranges[MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME].mean()), 
                                            key="app3_fert_temp_main")
        user_inputs[MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME] = temp_f_val
        
        # Other inputs (assuming their names are consistent and correct in data_for_input_ranges)
        user_inputs['Humidity'] = st.sidebar.slider('á‹¨áŠ á‹¨áˆ­ áŠ•á‰¥áˆ¨á‰µ áŠ¥áˆ­áŒ¥á‰ á‰µ (%)', int(data_for_input_ranges.get('Humidity', pd.Series([0,100,50])).min()), int(data_for_input_ranges.get('Humidity', pd.Series([0,100,50])).max()), int(data_for_input_ranges.get('Humidity', pd.Series([0,100,50])).mean()), key="app3_fert_hum_main")
        user_inputs['Moisture'] = st.sidebar.slider('á‹¨áŠ áˆáˆ­ áŠ¥áˆ­áŒ¥á‰ á‰µ (%)', int(data_for_input_ranges.get('Moisture', pd.Series([0,100,50])).min()), int(data_for_input_ranges.get('Moisture', pd.Series([0,100,50])).max()), int(data_for_input_ranges.get('Moisture', pd.Series([0,100,50])).mean()), key="app3_fert_moist_main")
        user_inputs['Soil Type'] = st.sidebar.selectbox('á‹¨áŠ áˆáˆ­ áŠ á‹­áŠá‰µ', sorted(list(soil_types_list)) if soil_types_list is not None else [], key="app3_fert_soil_main")
        user_inputs['Crop Type'] = st.sidebar.selectbox('á‹¨áˆ°á‰¥áˆ áŠ á‹­áŠá‰µ', sorted(list(crop_types_list)) if crop_types_list is not None else [], key="app3_fert_crop_main")
        user_inputs['Nitrogen'] = st.sidebar.slider('á‹¨áŠ“á‹­á‰µáˆ®áŒ…áŠ• áˆ˜áŒ áŠ• (kg/ha)', int(data_for_input_ranges.get('Nitrogen', pd.Series([0,100,20])).min()), int(data_for_input_ranges.get('Nitrogen', pd.Series([0,100,20])).max()), int(data_for_input_ranges.get('Nitrogen', pd.Series([0,100,20])).mean()), key="app3_fert_n_main")
        user_inputs['Potassium'] = st.sidebar.slider('á‹¨á–á‰³áˆ²á‹¨áˆ áˆ˜áŒ áŠ• (kg/ha)', int(data_for_input_ranges.get('Potassium', pd.Series([0,100,10])).min()), int(data_for_input_ranges.get('Potassium', pd.Series([0,100,10])).max()), int(data_for_input_ranges.get('Potassium', pd.Series([0,100,10])).mean()), key="app3_fert_k_main")
        user_inputs['Phosphorous'] = st.sidebar.slider('á‹¨ááˆµáˆáˆ¨áˆµ áˆ˜áŒ áŠ• (kg/ha)', int(data_for_input_ranges.get('Phosphorous', pd.Series([0,100,10])).min()), int(data_for_input_ranges.get('Phosphorous', pd.Series([0,100,10])).max()), int(data_for_input_ranges.get('Phosphorous', pd.Series([0,100,10])).mean()), key="app3_fert_p_main")
        
        # Create DataFrame using the keys from user_inputs dictionary
        # This ensures column names in the DataFrame match the keys used above.
        return pd.DataFrame({k: [v] for k, v in user_inputs.items()})

    if unique_soil_types_fert is not None and unique_crop_types_fert is not None and df_for_ranges_fert is not None:
        input_df_fert = get_user_inputs_fert(unique_soil_types_fert, unique_crop_types_fert, df_for_ranges_fert)
        st.subheader('áŠ¥áˆ­áˆµá‹ á‹«áˆµáŒˆá‰¡á‰µ áˆ˜áˆ¨áŒƒ (áˆˆáˆ›á‹³á‰ áˆªá‹«)á¦')
        st.dataframe(input_df_fert) # Displaying the DF sent for prediction
        
        if st.button('ğŸ’¡ á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥ áŠ áŒáŠ', use_container_width=True, key="app3_fert_recommend_btn_main"):
            with st.spinner("áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥ áŠ¥á‹¨á‰°á‹˜áŒ‹áŒ€ áŠá‹..."):
                try:
                    # Ensure the input DataFrame columns match what the pipeline expects.
                    # The pipeline's preprocessor's `ColumnTransformer` is fitted on specific column names.
                    # If MODEL_EXPECTED_TEMPERATURE_COLUMN_NAME was 'Temparature' (a), and input_df_fert has it, it should work.
                    
                    prediction_encoded_fert = pipeline_fert.predict(input_df_fert)
                    predicted_fertilizer_name_fert = LEncoder_fert.inverse_transform(prediction_encoded_fert)
                    st.subheader('á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥á¦')
                    st.success(f"áˆˆáŠ¥áˆ­áˆµá‹ áˆáŠ”á‰³ á‰°áˆµáˆ›áˆš á‹¨áˆ†áŠá‹ áˆ›á‹³á‰ áˆªá‹«á¦ **{predicted_fertilizer_name_fert[0]}** áŠá‹")
                    st.balloons()
                except ValueError as ve: # Catch specific ValueError for missing columns
                    st.error(f"áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥ á‰ áˆ›á‹˜áŒ‹áŒ€á‰µ áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆ (áˆ›á‹³á‰ áˆªá‹«)á¦ {ve}")
                    st.error(f"á‹¨á‰€áˆ¨á‰ á‹ áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ (áˆˆá‰µáŠ•á‰ á‹«)á¦ {input_df_fert.columns.tolist()}")
                    # Try to get expected feature names from the pipeline if possible
                    if hasattr(pipeline_fert, 'feature_names_in_'):
                        st.error(f"áˆá‹´áˆ‰ á‹¨áˆšáŒ á‰¥á‰ƒá‰¸á‹ á‹¨áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ (áŠ¨á“á‹­á•áˆ‹á‹­áŠ•)á¦ {pipeline_fert.feature_names_in_}")
                    elif hasattr(pipeline_fert.named_steps.get('preprocessor'), 'get_feature_names_out'):
                         try:
                             st.error(f"áˆá‹´áˆ‰ á‹¨áˆšáŒ á‰¥á‰ƒá‰¸á‹ á‹¨áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ (áŠ¨á•áˆªá•áˆ®áˆ°áˆ°áˆ­)á¦ {pipeline_fert.named_steps['preprocessor'].get_feature_names_out()}")
                         except:
                             st.error("á‹¨á•áˆªá•áˆ®áˆ°áˆ°áˆ­ á‹¨áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½áŠ• áˆ›áŒáŠ˜á‰µ áŠ áˆá‰°á‰»áˆˆáˆá¢")
                    else:
                        st.error("á‹¨áˆá‹´áˆ‰áŠ• (preprocessor) á‹¨áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ áˆ›á‹ˆá‰… áŠ áˆá‰°á‰»áˆˆáˆá¢")

                except Exception as e_predict: 
                    st.error(f"áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥ á‰ áˆ›á‹˜áŒ‹áŒ€á‰µ áˆ‹á‹­ áˆ³áˆˆ á‹«áˆá‰³á‹ˆá‰€ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆ (áˆ›á‹³á‰ áˆªá‹«)á¦ {e_predict}")
                    st.error(f"á‹¨á‰€áˆ¨á‰ á‹ áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½á¦ {input_df_fert.columns.tolist()}")
    else:
        st.error("á‹¨áŠ áˆáˆ­ á‹ˆá‹­áˆ á‹¨áˆ°á‰¥áˆ áŠ á‹­áŠá‰¶á‰½áŠ• (áˆˆáˆ›á‹³á‰ áˆªá‹«) áŠ¨á‹³á‰³á‹ áˆ›áŒáŠ˜á‰µ áŠ áˆá‰°á‰»áˆˆáˆá¢")

# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 4: á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹«
# ==============================================================================
def run_crop_yield_app():
    st.header("ğŸŒ¾ á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áˆµáˆ­á‹“á‰µ")
    st.markdown("á‹¨á‰°áˆˆá‹«á‹© áˆ˜áˆ¨áŒƒá‹á‰½áŠ• á‰ áˆ›áˆµáŒˆá‰£á‰µ á‹¨áˆšáŒ á‰ á‰€á‹áŠ• á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰³áˆ›áŠá‰µ (Yield) á‹­á‰°áŠ•á‰¥á‹©á¢")

    DATA_FILE_PATH_YIELD = get_project_file_path("04_crop_yield_prediction", "crop_yield_data.csv")
    MODEL_PIPELINE_FILE_PATH_YIELD = get_project_file_path("04_crop_yield_prediction", "crop_yield_model_pipeline.joblib")

    @st.cache_data
    def load_data_yield(file_path):
        try:
            df = pd.read_csv(file_path)
            df.columns = df.columns.str.strip()
            for col in df.select_dtypes(include=np.number).columns:
                if df[col].isnull().any(): df[col].fillna(df[col].median(), inplace=True)
            for col in df.select_dtypes(include='object').columns:
                if df[col].isnull().any(): df[col].fillna(df[col].mode()[0], inplace=True)
            if 'Production' in df.columns and df['Production'].dtype == 'object':
                df['Production'] = pd.to_numeric(df['Production'], errors='coerce')
                numeric_production = df['Production'].dropna()
                df['Production'].fillna(numeric_production.median() if not numeric_production.empty else 0, inplace=True)
            if 'Yield' not in df.columns:
                if 'Production' in df.columns and 'Area' in df.columns:
                    df['Yield'] = df.apply(lambda row: row['Production'] / row['Area'] if row['Area'] != 0 else 0, axis=1)
                    df['Yield'].replace([np.inf, -np.inf], np.nan, inplace=True)
                    df['Yield'].fillna(df['Yield'].median(), inplace=True)
                else:
                    st.error("á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‹³á‰³ 'Yield' á‹“áˆá‹µ á‹ˆá‹­áˆ áŠ¥áˆ±áŠ• áˆˆáˆ˜ááŒ áˆ­ á‹¨áˆšá‹«áˆµá‰½áˆ‰ 'Production' áŠ¥áŠ“ 'Area' á‹“áˆá‹¶á‰½ á‹¨áˆ‰á‰µáˆá¢")
                    return None
            return df
        except FileNotFoundError: st.error(f"á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‹³á‰³ á‹á‹­áˆ áŠ áˆá‰°áŒˆáŠ˜áˆá¦ {file_path}"); return None
        except Exception as e: st.error(f"á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‹³á‰³ á‰ áˆ˜áŒ«áŠ• áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}"); return None

    df_yield_data = load_data_yield(DATA_FILE_PATH_YIELD)

    @st.cache_resource
    def train_or_load_yield_model_pipeline(data_frame):
        if data_frame is None: return None, None, None, None, None, None
        target_col_y = 'Yield'
        # Ensure Yield is present before dropping
        if target_col_y not in data_frame.columns:
            st.error(f"á‹’áˆ‹áˆ› á‹“áˆá‹µ '{target_col_y}' á‰ áˆ°á‰¥áˆ áˆáˆ­á‰µ á‹³á‰³ á‹áˆµáŒ¥ á‹¨áˆˆáˆá¢")
            return None, None, None, None, None, None

        features_to_drop_y = [target_col_y, 'Production'] # Production also often dropped if Yield is derived
        X_y = data_frame.drop(columns=[col for col in features_to_drop_y if col in data_frame.columns], axis=1)
        y_y = data_frame[target_col_y]
        
        categorical_features_y = X_y.select_dtypes(include='object').columns.tolist()
        numerical_features_y = X_y.select_dtypes(include=np.number).columns.tolist()
        
        if not numerical_features_y and not categorical_features_y : # Check if X_y is empty
            st.error("áˆáŠ•áˆ á‹¨áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½ (features) áˆˆáˆ°á‰¥áˆ áˆáˆ­á‰µ áˆá‹´áˆ áŠ áˆá‰°áŒˆáŠ™áˆá¢")
            return None, None, None, None, None, None

        preprocessor_y = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_features_y),
                ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features_y)],
            remainder='drop') # Drop any other columns not specified
        
        model_pipeline_y = Pipeline(steps=[
            ('preprocessor', preprocessor_y),
            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))])

        if os.path.exists(MODEL_PIPELINE_FILE_PATH_YIELD):
            try:
                loaded_pipeline = joblib.load(MODEL_PIPELINE_FILE_PATH_YIELD)
                # To get feature names, it's best if they were saved during training
                # For now, derive from data_frame like before
                temp_X_y = data_frame.drop(columns=[col for col in features_to_drop_y if col in data_frame.columns], axis=1)
                feature_names_out = temp_X_y.columns.tolist()
                return (loaded_pipeline, data_frame['Crop'].unique(), data_frame['Season'].unique(), data_frame['State'].unique(), data_frame, feature_names_out)
            except Exception as e: st.sidebar.warning(f"á‹¨á‰°á‰€áˆ˜áŒ  á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ áˆá‹´áˆ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆ ({e})á¢ áŠ á‹²áˆµ á‰ áˆ›áˆ°áˆáŒ áŠ• áˆ‹á‹­...")

        X_train_y, X_test_y, y_train_y, y_test_y = train_test_split(X_y, y_y, test_size=0.2, random_state=42)
        model_pipeline_y.fit(X_train_y, y_train_y)
        r2_y = model_pipeline_y.score(X_test_y, y_test_y)
        rmse_y = np.sqrt(mean_squared_error(y_test_y, model_pipeline_y.predict(X_test_y)))
        st.sidebar.metric(label="á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ áˆá‹´áˆ RÂ² (áŠ á‹²áˆµ á‹¨áˆ°áˆˆáŒ áŠ)", value=f"{r2_y:.3f}", key="app4_yield_r2_retrained")
        st.sidebar.metric(label="á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ áˆá‹´áˆ RMSE (áŠ á‹²áˆµ á‹¨áˆ°áˆˆáŒ áŠ)", value=f"{rmse_y:.3f}", key="app4_yield_rmse_retrained")
        try: joblib.dump(model_pipeline_y, MODEL_PIPELINE_FILE_PATH_YIELD)
        except Exception as e_save: st.sidebar.error(f"á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ áˆá‹´áˆ áˆ›áˆµá‰€áˆ˜áŒ¥ áŠ áˆá‰°á‰»áˆˆáˆá¦ {e_save}")
        return (model_pipeline_y, data_frame['Crop'].unique(), data_frame['Season'].unique(), data_frame['State'].unique(), data_frame, X_y.columns.tolist())

    if df_yield_data is None: st.error("á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‹³á‰³ áˆ˜áŒ«áŠ• áˆµáˆ‹áˆá‰°á‰»áˆˆ á‹­áˆ… áˆ˜áˆ³áˆªá‹« áŠ á‹­áˆ°áˆ«áˆá¢"); st.stop()
    pipeline_y, unique_crops_y, unique_seasons_y, unique_states_y, df_for_ranges_y, feature_names_y = train_or_load_yield_model_pipeline(df_yield_data)
    
    if not pipeline_y or not feature_names_y or df_for_ranges_y is None:
        st.error("á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áˆá‹´áˆ á‹ˆá‹­áˆ áŠ áˆµáˆáˆ‹áŒŠ áˆ˜áˆ¨áŒƒá‹á‰½ áŠ áˆá‰°áŒ«áŠ‘áˆá¢")
        st.stop()


    st.sidebar.subheader("á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áˆ˜áˆ¨áŒƒ á‹«áˆµáŒˆá‰¡")
    def get_user_yield_inputs(crops_list, seasons_list, states_list, data_for_input_ranges, model_expected_features):
        inputs = {}
        current_real_year_y = datetime.date.today().year
        
        # Ensure inputs are only created for features the model expects
        if 'Crop_Year' in model_expected_features:
            min_crop_year_data_y = int(data_for_input_ranges['Crop_Year'].min()) if 'Crop_Year' in data_for_input_ranges.columns and not data_for_input_ranges['Crop_Year'].empty else current_real_year_y - 10
            max_crop_year_data_y = int(data_for_input_ranges['Crop_Year'].max()) if 'Crop_Year' in data_for_input_ranges.columns and not data_for_input_ranges['Crop_Year'].empty else current_real_year_y
            default_crop_year_val_y = min(current_real_year_y, max_crop_year_data_y)
            max_input_year_y = max(max_crop_year_data_y, current_real_year_y + 2)
            inputs['Crop_Year'] = st.sidebar.number_input('á‹¨áˆ°á‰¥áˆ áŠ áˆ˜á‰µ (áˆˆáˆáˆ­á‰µ)', min_value=min_crop_year_data_y, max_value=max_input_year_y, value=default_crop_year_val_y, step=1, key="app4_yield_year")
        
        if 'Crop' in model_expected_features: inputs['Crop'] = st.sidebar.selectbox('á‹¨áˆ°á‰¥áˆ áŠ á‹­áŠá‰µ (áˆˆáˆáˆ­á‰µ)', sorted(list(crops_list)) if crops_list is not None else [], key="app4_yield_crop")
        if 'Season' in model_expected_features: inputs['Season'] = st.sidebar.selectbox('á‹ˆá‰…á‰µ (áˆˆáˆáˆ­á‰µ)', sorted(list(seasons_list)) if seasons_list is not None else [], key="app4_yield_season")
        if 'State' in model_expected_features: inputs['State'] = st.sidebar.selectbox('áŒá‹›á‰µ/áŠ­áˆáˆ (áˆˆáˆáˆ­á‰µ)', sorted(list(states_list)) if states_list is not None else [], key="app4_yield_state")

        num_inputs_def_y = {
            'Area': ('á‹¨áˆˆáˆ› áˆ˜áˆ¬á‰µ áˆµá‹á‰µ (áˆ„áŠ­á‰³áˆ­)', 1000.0, 100.0, "%.2f"),
            'Annual_Rainfall': ('áŠ áˆ˜á‰³á‹Š á‹¨á‹áŠ“á‰¥ áˆ˜áŒ áŠ• (mm)', 1200.0, 50.0, "%.2f"),
            'Fertilizer': ('á‹¨áˆ›á‹³á‰ áˆªá‹« áˆ˜áŒ áŠ• (kg)', 50000.0, 1000.0, "%.2f"),
            'Pesticide': ('á‹¨á€áˆ¨-á‰°á‰£á‹­ áˆ˜áŒ áŠ• (kg/L)', 500.0, 100.0, "%.2f")}
        
        for feature, (label, def_val, step, fmt) in num_inputs_def_y.items():
            if feature in model_expected_features:
                min_val = float(data_for_input_ranges[feature].min()) if feature in data_for_input_ranges.columns and not data_for_input_ranges[feature].empty else 0.0
                max_val = float(data_for_input_ranges[feature].max()) if feature in data_for_input_ranges.columns and not data_for_input_ranges[feature].empty else def_val * 5
                mean_val = float(data_for_input_ranges[feature].mean()) if feature in data_for_input_ranges.columns and not data_for_input_ranges[feature].empty else def_val
                inputs[feature] = st.sidebar.number_input(label, min_value=min_val, max_value=max_val, value=mean_val, step=step, format=fmt, key=f"app4_yield_{feature}")
        
        # Create DataFrame with only the features the model expects, in the correct order.
        user_data_dict = {key: [inputs.get(key)] for key in model_expected_features}

        # Handle cases where a model feature might not have a UI element (e.g., if logic error)
        for feature in model_expected_features:
            if feature not in user_data_dict or user_data_dict[feature][0] is None:
                # Fill with NaN or a sensible default if a feature was missed by UI for some reason
                # This should ideally not happen if model_expected_features drives UI creation
                user_data_dict[feature] = [np.nan]
                st.warning(f"á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ áŒá‰¥á‹“á‰µ '{feature}' áŠ áˆá‰°áŒˆáŠ˜áˆ á‹ˆá‹­áˆ á‰£á‹¶ áŠá‹á¢ á‰  NaN á‹­á‰°áŠ«áˆá¢")


        return pd.DataFrame(user_data_dict)[model_expected_features] # Enforce order

    input_df_y = get_user_yield_inputs(unique_crops_y, unique_seasons_y, unique_states_y, df_for_ranges_y, feature_names_y)
    st.subheader('áŠ¥áˆ­áˆµá‹ á‹«áˆµáŒˆá‰¡á‰µ áˆ˜áˆ¨áŒƒ (áˆˆáˆáˆ­á‰µ á‰µáŠ•á‰ á‹«)á¦')
    st.dataframe(input_df_y)
    if st.button('ğŸŒ¾ áˆáˆ­á‰³áˆ›áŠá‰µáŠ• á‰°áŠ•á‰¥á‹­', use_container_width=True, key="app4_yield_predict_btn"):
        with st.spinner("á‹¨áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áŠ¥á‹¨á‰°áˆ°áˆ« áŠá‹..."):
            try:
                predicted_yield_y = pipeline_y.predict(input_df_y)
                final_yield_y = max(0, predicted_yield_y[0]) # Ensure non-negative yield
                st.subheader('á‹¨á‰°á‰°áŠá‰ á‹¨á‹ á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰³áˆ›áŠá‰µ (Yield)á¦')
                st.success(f"á‰ áŒáˆá‰µ á‹¨áˆšáŒ á‰ á‰€á‹ áˆáˆ­á‰³áˆ›áŠá‰µá¦ **{final_yield_y:.3f}** (áˆ˜áˆˆáŠªá‹« áŠ áˆƒá‹± á‰ á‹‹áŠ“á‹ á‹³á‰³ áˆ˜áˆ°áˆ¨á‰µ)")
            except Exception as e: st.error(f"á‹¨áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}")


# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 5: á‹¨áŠ áˆ›áˆ­áŠ› AI á‰»á‰µá‰¦á‰µ (Gemini)
# ==============================================================================
def run_chatbot_app():
    st.header("ğŸ¤– á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŠ áˆ›áŠ«áˆª (AI Chatbot)")
    st.caption("á‰ áŠ áˆ›áˆ­áŠ› áˆµáˆˆ áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŒ‰á‹³á‹®á‰½ á‹­áŒ á‹­á‰")

    if not GENAI_AVAILABLE:
        st.error("á‹¨ 'google-generativeai' á“áŠ¬áŒ… áŠ áˆá‰°áŒ«áŠáˆá¢ áŠ¥á‰£áŠ­á‹ á‹­áŒ«áŠ‘á‰µá¦ `pip install google-generativeai`")
        st.stop()

    GEMINI_API_KEY_CHATBOT = st.secrets.get("GEMINI_API_KEY_CHATBOT_MAIN", st.secrets.get("GEMINI_API_KEY")) # Try specific then general
    if not GEMINI_API_KEY_CHATBOT: GEMINI_API_KEY_CHATBOT = os.environ.get("GEMINI_API_KEY_CHATBOT_MAIN", os.environ.get("GEMINI_API_KEY"))
    
    if not GEMINI_API_KEY_CHATBOT:
        st.sidebar.subheader("á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆá (áˆˆá‰»á‰µá‰¦á‰µ)")
        GEMINI_API_KEY_CHATBOT_INPUT = st.sidebar.text_input("á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆáá‹áŠ• áŠ¥á‹šáˆ… á‹«áˆµáŒˆá‰¡á¦", type="password", key="app5_gemini_api_key")
        if GEMINI_API_KEY_CHATBOT_INPUT: GEMINI_API_KEY_CHATBOT = GEMINI_API_KEY_CHATBOT_INPUT
        else: st.warning("âš ï¸ á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆá (áˆˆá‰»á‰µá‰¦á‰µ) áŠ áˆá‰°áŒˆáŠ˜áˆá¢"); st.stop()
    
    try: genai.configure(api_key=GEMINI_API_KEY_CHATBOT)
    except Exception as e: st.error(f"á‹¨ Gemini áŠ¤á’áŠ á‹­ á‰áˆááŠ• (áˆˆá‰»á‰µá‰¦á‰µ) á‰ áˆ›á‹‹á‰€áˆ­ áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}"); st.stop()

    MODEL_NAME_CHATBOT = "gemini-1.5-flash" # Or other suitable model
    SYSTEM_PROMPT_AMHARIC_CHATBOT = """áˆ°áˆ‹áˆ! áŠ áŠ•á‰° á‹¨áˆá‰µáŠ“áŒˆáˆ¨á‹ á‰ áŠ áˆ›áˆ­áŠ› á‰¥á‰» áŠá‹á¢ áŠ¥áŠ” áˆµáˆˆ áŠ¢á‰µá‹®áŒµá‹« áŒá‰¥áˆ­áŠ“á£ áŠ á‹áˆ˜áˆ« áŠ áˆ˜áˆ«áˆ¨á‰µá£ á‹¨áŠ¥áŠ•áˆµáˆ³á‰µ áŠ¥áˆ­á‰£á‰³ á‹˜á‹´á‹á‰½ã€ á‹¨áŠ áˆáˆ­áŠ“ á‹áˆƒ áŠ á‹«á‹«á‹ã€ á‹¨áˆ°á‰¥áˆ á‰°á‰£á‹­áŠ“ á‰ áˆ½á‰³ á‰áŒ¥áŒ¥áˆ­ã€ á‹˜áˆ˜áŠ“á‹Š á‹¨áŒá‰¥áˆ­áŠ“ á‰´áŠ­áŠ–áˆáŒ‚á‹á‰½ã€ á‹¨áˆáŒá‰¥ áŠ á‹­áŠá‰¶á‰½ã€ á‹¨áˆáŒá‰¥ á‹áŒáŒ…á‰µã€ á‹¨áˆáŒá‰¥ á‹°áˆ…áŠ•áŠá‰µã€ áŠ¥áŠ“ áˆµáŠ-áˆáŒá‰¥ áŒ‰á‹³á‹®á‰½ áˆ˜áˆ¨áŒƒ áˆˆáˆ˜áˆµáŒ á‰µáŠ“ áˆˆáˆ˜á‹ˆá‹«á‹¨á‰µ á‹¨á‰°á‹˜áŒ‹áŒ€áˆ á‹¨áˆ°á‹ áˆ°áˆ«áˆ½ á‹¨áˆ›áˆ°á‰¥ á‰½áˆá‰³ áˆ¨á‹³á‰µ áŠáŠá¢ áŠ¥á‰£áŠ­á‹áŠ• áŒ¥á‹«á‰„á‹áŠ• á‰ áŠ¥áŠá‹šáˆ… áˆ­á‹•áˆ¶á‰½ á‹™áˆªá‹« á‰¥á‰» á‹«á‰…áˆ­á‰¡á¢ áŠ¨áŠ¥áŠá‹šáˆ… áˆ­á‹•áˆ¶á‰½ á‹áŒª áˆˆáˆšá‰€áˆ­á‰¡ áŒ¥á‹«á‰„á‹á‰½ áˆ˜áˆáˆµ áˆˆáˆ˜áˆµáŒ á‰µáˆ áˆ†áŠ áˆˆáˆ˜á‹ˆá‹«á‹¨á‰µ áŠ áˆá‰°áˆá‰€á‹°áˆáŠáˆá¢ á‰ áŒá‰¥áˆ­áŠ“ á‹ˆá‹­áˆ á‰ áˆáŒá‰¥ áŠáŠ­ áŒ‰á‹³á‹­ áˆ‹á‹­ áˆáŠ• áˆáˆ­á‹³á‹á‰µ?"""


    try:
        if "app5_chat_session" not in st.session_state:
            model_chatbot = genai.GenerativeModel(MODEL_NAME_CHATBOT, system_instruction=SYSTEM_PROMPT_AMHARIC_CHATBOT)
            st.session_state.app5_chat_session = model_chatbot.start_chat(history=[])
    except Exception as e: st.error(f"á‹¨ Gemini áˆá‹´áˆáŠ• (áˆˆá‰»á‰µá‰¦á‰µ) á‰ áˆ›áˆµáŒ€áˆ˜áˆ­ áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}"); st.stop()

    if "app5_chat_messages" not in st.session_state: st.session_state.app5_chat_messages = []

    for message in st.session_state.app5_chat_messages:
        with st.chat_message(message["role"]): st.markdown(message["parts"][0]["text"])

    user_prompt_chatbot = st.chat_input("áŒ¥á‹«á‰„á‹áŠ• áŠ¥á‹šáˆ… á‰ áŠ áˆ›áˆ­áŠ› á‹­áŒ»á‰ (áˆˆá‰»á‰µá‰¦á‰µ)...", key="app5_chat_input")
    if user_prompt_chatbot:
        st.session_state.app5_chat_messages.append({"role": "user", "parts": [{"text": user_prompt_chatbot}]})
        with st.chat_message("user"): st.markdown(user_prompt_chatbot)
        
        with st.chat_message("model"):
            message_placeholder_chatbot = st.empty()
            full_response_text_chatbot = ""
            try:
                response_chatbot = st.session_state.app5_chat_session.send_message(user_prompt_chatbot, stream=True)
                for chunk in response_chatbot:
                    text_part = None
                    if hasattr(chunk, 'text') and chunk.text:
                        text_part = chunk.text
                    elif hasattr(chunk, 'parts') and chunk.parts and hasattr(chunk.parts[0], 'text') and chunk.parts[0].text:
                        text_part = chunk.parts[0].text
                    
                    if text_part:
                        full_response_text_chatbot += text_part
                        message_placeholder_chatbot.markdown(full_response_text_chatbot + "â–Œ")
                message_placeholder_chatbot.markdown(full_response_text_chatbot)
            except Exception as e_chat:
                full_response_text_chatbot = f"á‹¨á‰»á‰µá‰¦á‰µ áˆáˆ‹áˆ½ á‰ áˆ›áŒáŠ˜á‰µ áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e_chat}"
                message_placeholder_chatbot.error(full_response_text_chatbot)
        st.session_state.app5_chat_messages.append({"role": "model", "parts": [{"text": full_response_text_chatbot}]})

    if st.sidebar.button("á‹¨á‰»á‰µá‰¦á‰µ á‹á‹­á‹­á‰±áŠ• áŠ áŒ½á‹³", key="app5_clear_chat_btn"):
        st.session_state.app5_chat_messages = []
        if "app5_chat_session" in st.session_state: del st.session_state.app5_chat_session 
        st.rerun()


# ==============================================================================
# áˆ˜á‰°áŒá‰ áˆªá‹« 6: á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­
# ==============================================================================
def run_agri_planner_app():
    st.header("ğŸ› ï¸ á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­ áŠ¥áŠ“ áˆ›áˆ˜á‰»á‰»")
    st.markdown("á‹¨á‰°áˆˆá‹«á‹© á‹¨áŒá‰¥áˆ­áŠ“ áŒá‰¥á‹“á‰¶á‰½áŠ• áŠ¥áŠ“ á‹¨áˆ˜á‹áˆªá‹« áŒŠá‹œá‹á‰½áŠ• á‰ áˆ›áˆµáŒˆá‰£á‰µ á‹¨áˆšáŒ á‰ á‰€á‹áŠ• á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰³áˆ›áŠá‰µ (Yield) áˆˆáˆ˜áŒˆáˆ˜á‰µ á‹­áˆ¨á‹³á‹á‰³áˆá¢")

    # Planner uses the model from App 4 (Crop Yield Prediction)
    MODEL_PIPELINE_FILE_PATH_PLANNER = get_project_file_path("04_crop_yield_prediction", "crop_yield_model_pipeline.joblib")
    DATA_FILE_PATH_PLANNER_INFO = get_project_file_path("04_crop_yield_prediction", "crop_yield_data.csv") # For input ranges and unique values

    @st.cache_resource
    def load_planner_model_and_data_info(model_path, data_path):
        model_p = None; df_info_p = None; features_p_list = None
        if not os.path.exists(model_path):
            st.error(f"á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹« áˆá‹´áˆ á‹á‹­áˆ (áˆˆáŠ¥á‰…á‹µ) áŠ áˆá‰°áŒˆáŠ˜áˆá¦ {model_path}"); return None, None, None
        try: model_p = joblib.load(model_path)
        except Exception as e: st.error(f"á‹¨á‰µáŠ•á‰ á‹« áˆá‹´áˆ‰áŠ• (áˆˆáŠ¥á‰…á‹µ) á‰ áˆ˜áŒ«áŠ• áˆ‹á‹­ áˆ³áˆˆ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e}"); return None, None, None

        if os.path.exists(data_path):
            try:
                # Load data similar to App 4 for consistency
                df_temp_p = pd.read_csv(data_path)
                df_temp_p.columns = df_temp_p.columns.str.strip()
                # Basic cleaning for info extraction
                for col in df_temp_p.select_dtypes(include=np.number).columns:
                    if df_temp_p[col].isnull().any(): df_temp_p[col].fillna(df_temp_p[col].median(), inplace=True)
                for col in df_temp_p.select_dtypes(include='object').columns:
                    if df_temp_p[col].isnull().any(): df_temp_p[col].fillna(df_temp_p[col].mode()[0], inplace=True)

                if 'Production' in df_temp_p.columns and df_temp_p['Production'].dtype == 'object':
                    df_temp_p['Production'] = pd.to_numeric(df_temp_p['Production'], errors='coerce')
                    numeric_prod_p = df_temp_p['Production'].dropna()
                    df_temp_p['Production'].fillna(numeric_prod_p.median() if not numeric_prod_p.empty else 0, inplace=True)

                if 'Yield' not in df_temp_p.columns and 'Production' in df_temp_p.columns and 'Area' in df_temp_p.columns:
                     df_temp_p['Yield'] = df_temp_p.apply(lambda row: row['Production'] / row['Area'] if row['Area'] != 0 else 0, axis=1)
                     df_temp_p['Yield'].replace([np.inf, -np.inf], np.nan, inplace=True)
                     df_temp_p['Yield'].fillna(df_temp_p['Yield'].median(), inplace=True)
                
                features_to_drop_p_info = ['Yield', 'Production']
                df_info_p = df_temp_p.copy() # Use a copy for info, original df_temp_p might be modified
                features_p_list = df_temp_p.drop(columns=[col for col in features_to_drop_p_info if col in df_temp_p.columns], axis=1).columns.tolist()

            except Exception as e_data: st.warning(f"á‹¨á‰€á‹µáˆá‹áŠ• á‹³á‰³ á‹á‹­áˆ (áˆˆáŠ¥á‰…á‹µ) áˆˆáˆ›áŒ£á‰€áˆ» áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¦ {e_data}")
        else: st.warning(f"á‹¨á‰€á‹µáˆá‹ á‹³á‰³ á‹á‹­áˆ (áˆˆáŠ¥á‰…á‹µ) áˆˆáˆ›áŒ£á‰€áˆ» áŠ áˆá‰°áŒˆáŠ˜áˆá¢")
        return model_p, df_info_p, features_p_list # df_info_p is the full dataframe for ranges

    pipeline_planner, df_info_planner, model_features_planner = load_planner_model_and_data_info(MODEL_PIPELINE_FILE_PATH_PLANNER, DATA_FILE_PATH_PLANNER_INFO)

    if not pipeline_planner: st.error("á‹¨áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­ áˆá‹´áˆ áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢"); st.stop()
    
    if not model_features_planner:
        # Fallback if features_p_list couldn't be determined
        # This should match the features the model from App 4 was trained on.
        # Crucially, decide if 'Planting_Month_Num' is part of this model.
        # If not, the form needs to use 'Season'.
        model_features_planner = ['Crop_Year', 'Crop', 'Season', 'State', 'Area', 'Annual_Rainfall', 'Fertilizer', 'Pesticide']
        # If Planting_Month_Num is a desired feature, the model needs to be retrained with it.
        # For now, let's assume the model from App 4 does NOT use Planting_Month_Num explicitly.
        # model_features_planner.append('Planting_Month_Num') # Add this if model supports it
        st.warning("á‹¨áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­ áˆá‹´áˆ áŒá‰¥á‹“á‰µ á‹“áˆá‹¶á‰½áŠ• áˆ›áŒáŠ˜á‰µ áŠ áˆá‰°á‰»áˆˆáˆá¢ áŠá‰£áˆª á‹“áˆá‹¶á‰½ (á‹«áˆˆ áˆ˜á‹áˆªá‹« á‹ˆáˆ­ á‰áŒ¥áˆ­) áŒ¥á‰…áˆ áˆ‹á‹­ á‹­á‹áˆ‹áˆ‰á¢")
    
    if df_info_planner is None:
        st.warning("á‹¨áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­ á‹¨á‹³á‰³ áˆ˜áˆ¨áŒƒ (áˆˆá‹ˆáˆ°áŠ–á‰½) áˆ˜áŒ«áŠ• áŠ áˆá‰°á‰»áˆˆáˆá¢ áŠá‰£áˆª á‹¨áŒá‰¥á‹“á‰µ á‹ˆáˆ°áŠ–á‰½ áŒ¥á‰…áˆ áˆ‹á‹­ á‹­á‹áˆ‹áˆ‰á¢")


    st.subheader("á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áˆ˜áˆˆáŠªá‹«á‹á‰½áŠ• á‹«áˆµáŒˆá‰¡")
    if 'app6_scenarios' not in st.session_state: st.session_state.app6_scenarios = []
    if 'app6_scenario_counter' not in st.session_state: st.session_state.app6_scenario_counter = 0

    # Use a unique key for the form based on scenario_counter to ensure it's fresh
    with st.form(key=f"app6_scenario_form_{st.session_state.app6_scenario_counter}"):
        st.write(f"áŠ á‹²áˆµ áŠ¥á‰…á‹µ (Scenario) #{len(st.session_state.app6_scenarios) + 1}")
        current_scenario_inputs_p = {}
        form_cols_p = st.columns(3) # Adjust number of columns as needed
        col_idx_p = 0

        # Define unique values for dropdowns, with fallbacks if df_info_planner is None
        unique_crops_p = sorted(df_info_planner['Crop'].unique()) if df_info_planner is not None and 'Crop' in df_info_planner.columns else ["áˆµáŠ•á‹´", "áŒ¤á", "á‰ á‰†áˆ"]
        unique_seasons_p = sorted(df_info_planner['Season'].unique()) if df_info_planner is not None and 'Season' in df_info_planner.columns else ["áŠ¨áˆ¨áˆá‰µ", "á‰ áˆáŒ", "áˆ™áˆ‰ áŠ áˆ˜á‰µ"]
        unique_states_p = sorted(df_info_planner['State'].unique()) if df_info_planner is not None and 'State' in df_info_planner.columns else ["áŠ¦áˆ®áˆšá‹«", "áŠ áˆ›áˆ«", "á‹°á‰¡á‰¥"]
        
        # planting_months_am_p is for display if we map a numeric month. The model itself might use 'Season'.
        planting_months_am_p = {"áˆ˜áˆµáŠ¨áˆ¨áˆ": 9, "áŒ¥á‰…áˆá‰µ": 10, "áˆ…á‹³áˆ­": 11, "á‰³áˆ…áˆ³áˆµ": 12, "áŒ¥áˆ­": 1, "á‹¨áŠ«á‰²á‰µ": 2, "áˆ˜áŒ‹á‰¢á‰µ": 3, "áˆšá‹«á‹á‹«": 4, "áŒáŠ•á‰¦á‰µ": 5, "áˆ°áŠ”": 6, "áˆ€áˆáˆŒ": 7, "áŠáˆáˆ´": 8}


        current_real_year_p = datetime.date.today().year
        if 'Crop_Year' in model_features_planner:
            min_cy_p = int(df_info_planner['Crop_Year'].min()) if df_info_planner is not None and 'Crop_Year' in df_info_planner.columns and not df_info_planner['Crop_Year'].empty else current_real_year_p - 5
            max_cy_data_p = int(df_info_planner['Crop_Year'].max()) if df_info_planner is not None and 'Crop_Year' in df_info_planner.columns and not df_info_planner['Crop_Year'].empty else current_real_year_p
            def_cy_p = min(current_real_year_p, max_cy_data_p)
            max_in_cy_p = max(max_cy_data_p, current_real_year_p + 1)
            current_scenario_inputs_p['Crop_Year'] = form_cols_p[col_idx_p % 3].number_input("á‹¨áˆ°á‰¥áˆ áŠ áˆ˜á‰µ (áˆˆáŠ¥á‰…á‹µ)", min_value=min_cy_p, max_value=max_in_cy_p, value=def_cy_p, step=1, key=f"app6_year_{st.session_state.app6_scenario_counter}")
            col_idx_p += 1

        # If model uses 'Planting_Month_Num'
        if 'Planting_Month_Num' in model_features_planner:
            sel_month_p_name = form_cols_p[col_idx_p % 3].selectbox("á‹¨áˆ˜á‹áˆªá‹« á‹ˆáˆ­ (áˆˆáŠ¥á‰…á‹µ)", list(planting_months_am_p.keys()), key=f"app6_month_{st.session_state.app6_scenario_counter}")
            current_scenario_inputs_p['Planting_Month_Num'] = planting_months_am_p[sel_month_p_name]
            col_idx_p += 1
        # Else if model uses 'Season' (more likely for App 4 model)
        elif 'Season' in model_features_planner:
             current_scenario_inputs_p['Season'] = form_cols_p[col_idx_p % 3].selectbox("á‹ˆá‰…á‰µ (áˆˆáŠ¥á‰…á‹µ)", unique_seasons_p, key=f"app6_season_{st.session_state.app6_scenario_counter}")
             col_idx_p +=1
        
        if 'Crop' in model_features_planner: 
            current_scenario_inputs_p['Crop'] = form_cols_p[col_idx_p % 3].selectbox("á‹¨áˆ°á‰¥áˆ áŠ á‹­áŠá‰µ (áˆˆáŠ¥á‰…á‹µ)", unique_crops_p, key=f"app6_crop_{st.session_state.app6_scenario_counter}")
            col_idx_p += 1
        if 'State' in model_features_planner: 
            current_scenario_inputs_p['State'] = form_cols_p[col_idx_p % 3].selectbox("áŠ­áˆáˆ/áŒá‹›á‰µ (áˆˆáŠ¥á‰…á‹µ)", unique_states_p, key=f"app6_state_{st.session_state.app6_scenario_counter}")
            col_idx_p += 1

        num_inputs_def_p = {
            'Area': ('á‹¨áˆˆáˆ› áˆ˜áˆ¬á‰µ áˆµá‹á‰µ (áˆ„áŠ­á‰³áˆ­)', 10.0, 1.0, "%.2f"), 
            'Annual_Rainfall': ('áŠ áˆ˜á‰³á‹Š á‹¨á‹áŠ“á‰¥ áˆ˜áŒ áŠ• (mm)', 1000.0, 50.0, "%.2f"), 
            'Fertilizer': ('á‹¨áˆ›á‹³á‰ áˆªá‹« áˆ˜áŒ áŠ• (kg)', 10000.0, 1000.0, "%.2f"), 
            'Pesticide': ('á‹¨á€áˆ¨-á‰°á‰£á‹­ áˆ˜áŒ áŠ• (kg/L)', 100.0, 10.0, "%.2f")
        }
        for feature, (label, def_val, step, fmt) in num_inputs_def_p.items():
            if feature in model_features_planner:
                min_val_p = float(df_info_planner[feature].min()) if df_info_planner is not None and feature in df_info_planner.columns and not df_info_planner[feature].empty else 0.0
                max_val_p = float(df_info_planner[feature].max()) if df_info_planner is not None and feature in df_info_planner.columns and not df_info_planner[feature].empty else def_val * 5 # Max 5 times default if no data
                mean_val_p = float(df_info_planner[feature].mean()) if df_info_planner is not None and feature in df_info_planner.columns and not df_info_planner[feature].empty else def_val
                current_scenario_inputs_p[feature] = form_cols_p[col_idx_p % 3].number_input(label, min_value=min_val_p, max_value=max_val_p, value=mean_val_p, step=step, format=fmt, key=f"app6_{feature}_{st.session_state.app6_scenario_counter}")
                col_idx_p += 1
        
        submit_button_planner = st.form_submit_button(label="â• á‹­áˆ…áŠ•áŠ• áŠ¥á‰…á‹µ áŒ¨áˆáˆ­ áŠ¥áŠ“ á‰°áŠ•á‰¥á‹­ (áˆˆáŠ áˆµáˆ˜áˆ³á‹­)")

    if submit_button_planner:
        # Create a DataFrame for prediction based on model_features_planner
        scenario_data_for_prediction = {}
        for feature_name in model_features_planner:
            if feature_name in current_scenario_inputs_p:
                scenario_data_for_prediction[feature_name] = [current_scenario_inputs_p[feature_name]]
            else:
                scenario_data_for_prediction[feature_name] = [np.nan] # Should be handled by preprocessor if trained to do so
                st.warning(f"á‹¨áŠ¥á‰…á‹µ áŒá‰¥á‹“á‰µ '{feature_name}' á‰ á‰…áŒ¹ á‹áˆµáŒ¥ áŠ áˆá‰°áŒˆáŠ˜áˆá¢ á‰  NaN á‹­áˆáˆ‹áˆá¢")
        
        scenario_df_p = pd.DataFrame(scenario_data_for_prediction)[model_features_planner] # Ensure order

        try:
            with st.spinner("á‹¨áˆáˆ­á‰³áˆ›áŠá‰µ á‰µáŠ•á‰ á‹« (áˆˆáŠ¥á‰…á‹µ) áŠ¥á‹¨á‰°áˆ°áˆ« áŠá‹..."):
                predicted_yield_p = pipeline_planner.predict(scenario_df_p)
                final_yield_p = max(0, predicted_yield_p[0]) # Ensure non-negative
            
            # Store the original inputs and the prediction for display
            scenario_to_store = current_scenario_inputs_p.copy()
            scenario_to_store['Predicted_Yield'] = round(final_yield_p, 3)
            
            st.session_state.app6_scenarios.append(scenario_to_store)
            st.session_state.app6_scenario_counter += 1 # To refresh the form
            st.success(f"áŠ¥á‰…á‹µ #{len(st.session_state.app6_scenarios)} á‰°áŒ¨áˆáˆ¯áˆ! á‹¨á‰°áŒˆáˆ˜á‰°á‹ áˆáˆ­á‰³áˆ›áŠá‰µá¦ {final_yield_p:.3f}")
            st.rerun() # Rerun to update the displayed scenarios and clear the form
        except Exception as e_p_predict: 
            st.error(f"á‹¨áŠ¥á‰…á‹µ á‰µáŠ•á‰ á‹« áˆ‹á‹­ áˆµáˆ…á‰°á‰µ á‰°áŠ¨áˆµá‰·áˆá¦ {e_p_predict}")
            st.error(f"áˆˆá‰µáŠ•á‰ á‹« á‹¨á‰€áˆ¨á‰¡ á‹“áˆá‹¶á‰½ (áˆˆáŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­)á¦ {scenario_df_p.columns.tolist()}")


    if st.session_state.app6_scenarios:
        st.subheader("á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áˆ›áŠáŒ»áŒ¸áˆªá‹«")
        scenarios_display_df_p = pd.DataFrame(st.session_state.app6_scenarios)
        
        # Prepare columns for display, including mapping month number to name if used
        display_cols_order_p = []
        if 'Planting_Month_Num' in scenarios_display_df_p.columns:
            num_to_month_am_p = {v: k for k, v in planting_months_am_p.items()}
            # Ensure the column exists before trying to map
            if 'Planting_Month_Num' in scenarios_display_df_p:
                 scenarios_display_df_p['á‹¨áˆ˜á‹áˆªá‹« á‹ˆáˆ­'] = scenarios_display_df_p['Planting_Month_Num'].map(num_to_month_am_p)
                 display_cols_order_p.append('á‹¨áˆ˜á‹áˆªá‹« á‹ˆáˆ­')
        
        # Add other input features that were part of the scenario
        for feature_p in current_scenario_inputs_p.keys(): # Use keys from the last submitted scenario as a guide
            if feature_p not in ['Predicted_Yield', 'Planting_Month_Num'] and feature_p in scenarios_display_df_p.columns:
                 display_cols_order_p.append(feature_p)

        if 'Predicted_Yield' in scenarios_display_df_p.columns: 
            display_cols_order_p.append('Predicted_Yield')
        
        # Ensure all columns in display_cols_order_p actually exist in scenarios_display_df_p
        final_display_columns_p = [col for col in display_cols_order_p if col in scenarios_display_df_p.columns]
        
        if final_display_columns_p:
            if 'Predicted_Yield' in final_display_columns_p:
                st.dataframe(scenarios_display_df_p[final_display_columns_p].sort_values(by='Predicted_Yield', ascending=False).reset_index(drop=True))
            else:
                 st.dataframe(scenarios_display_df_p[final_display_columns_p].reset_index(drop=True))
        else:
            st.write("áˆˆáˆ›áˆ³á‹¨á‰µ áˆáŠ•áˆ á‹¨á‰°á‹˜áŒ‹áŒ á‹¨áŠ¥á‰…á‹µ á‹“áˆá‹¶á‰½ á‹¨áˆ‰áˆá¢")


        if st.button("ğŸ—‘ï¸ áˆáˆ‰áŠ•áˆ áŠ¥á‰…á‹¶á‰½ áŠ áŒ½á‹³ (áˆˆáŠ áˆµáˆ˜áˆ³á‹­)", key="app6_clear_scenarios_btn"):
            st.session_state.app6_scenarios = []
            st.session_state.app6_scenario_counter = 0 # Reset counter to ensure form key is fresh
            st.rerun()
    else: st.info("áŠ¥áˆµáŠ«áˆáŠ• áˆáŠ•áˆ á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ (áˆˆáŠ áˆµáˆ˜áˆ³á‹­) áŠ áˆ‹áŠ¨áˆ‰áˆá¢ áŠ¨áˆ‹á‹­ áŠ«áˆˆá‹ á‰…áŒ½ á‰ áˆ˜áˆ™áˆ‹á‰µ á‹­áŒ€áˆáˆ©á¢")


# ==============================================================================
# --- á‹‹áŠ“ á‹¨áˆ˜á‰°áŒá‰ áˆªá‹« áŠ áˆ°áˆ³ (Navigation) ---
# ==============================================================================
if 'main_selected_app_name' not in st.session_state:
    st.session_state.main_selected_app_name = "ğŸ  á‹¨áˆ˜áŠáˆ» áŒˆáŒ½"

# Construct path for logo using the helper function
logo_path = get_project_file_path("assets", "smart_agri_logo.png")
if os.path.exists(logo_path):
    st.sidebar.image(logo_path, width=100)
else:
    st.sidebar.image("https://streamlit.io/images/brand/streamlit-logo-secondary-colormark-darktext.png", width=100) # Fallback

st.sidebar.title("á‹¨áˆ˜áˆ³áˆªá‹«á‹á‰½ áˆáˆ­áŒ«")

app_options_main = {
    "ğŸ  á‹¨áˆ˜áŠáˆ» áŒˆáŒ½": None,
    "1. á‹¨áŠ¥áŠ•áŒ€áˆ« áŒ¥áˆ«á‰µ áˆáˆ­áˆ˜áˆ«": run_injera_quality_app,
    "2. á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ á‰µáŠ•á‰ á‹«": run_milk_spoilage_app,
    "3. á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥": run_fertilizer_recommendation_app,
    "4. á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹«": run_crop_yield_app,
    "5. á‹¨áŒá‰¥áˆ­áŠ“ áŠ áˆ›áŠ«áˆª (AI Chatbot)": run_chatbot_app,
    "6. á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­": run_agri_planner_app
}

# Callback to update selected app name in session state
def update_main_selected_app():
    st.session_state.main_selected_app_name = st.session_state._main_selectbox_app_selection

# Use st.session_state.main_selected_app_name to set the index for the selectbox
try:
    current_selection_index = list(app_options_main.keys()).index(st.session_state.main_selected_app_name)
except ValueError:
    current_selection_index = 0 # Default to home page if current selection is invalid

st.sidebar.selectbox(
    "áŠ¥á‰£áŠ­á‹ áˆŠáŒ á‰€áˆ™á‰ á‰µ á‹¨áˆšáˆáˆáŒ‰á‰µáŠ• áˆ˜áˆ³áˆªá‹« á‹­áˆáˆ¨áŒ¡á¦",
    list(app_options_main.keys()),
    index=current_selection_index,
    on_change=update_main_selected_app,
    key="_main_selectbox_app_selection" 
)

# Display the selected app
if st.session_state.main_selected_app_name == "ğŸ  á‹¨áˆ˜áŠáˆ» áŒˆáŒ½":
    st.header("ğŸŒ¾ áŠ¥áŠ•áŠ³áŠ• á‹ˆá‹° áˆáˆ‰áŠ• áŠ á‰€á á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áˆµáˆ­á‹“á‰µ á‰ á‹°áˆ…áŠ“ áˆ˜áŒ¡!")
    st.markdown("""
    á‹­áˆ… áˆ˜á‹µáˆ¨áŠ­ á‹¨á‰°áˆˆá‹«á‹© á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŠáŠ­ á‰½áŒáˆ®á‰½áŠ• áˆˆáˆ˜áá‰³á‰µ á‹¨áˆšá‹«áŒá‹™ á‹˜áˆ˜áŠ“á‹Š á‹¨á‰´áŠ­áŠ–áˆáŒ‚ áˆ˜áá‰µáˆ„á‹á‰½áŠ• á‹«á‰€áˆ­á‰£áˆá¢
    áŠ¨áŒáˆ« á‰ áŠ©áˆ áŠ«áˆˆá‹ áˆáŠ“áˆŒ á‰ áˆ˜áˆáˆ¨áŒ¥ á‹¨áˆšáˆáˆáŒ‰á‰µáŠ• áˆ˜áˆ³áˆªá‹« áˆ˜áŒ á‰€áˆ á‹­á‰½áˆ‹áˆ‰á¢

    **á‹¨áˆšáŒˆáŠ™ áˆ˜áˆ³áˆªá‹«á‹á‰½ á‹áˆ­á‹áˆ­á¦**
    - **á‹¨áŠ¥áŠ•áŒ€áˆ« áŒ¥áˆ«á‰µ áˆáˆ­áˆ˜áˆ«:** á‹¨áŠ¥áŠ•áŒ€áˆ« áá‰¶ á‰ áˆ˜áŒ á‰€áˆ á‹¨áŒ¥áˆ«á‰µ á‹°áˆ¨áŒƒá‹áŠ• á‰ ááŒ¥áŠá‰µ á‹­á‹ˆá‰á¢
    - **á‹¨á‹ˆá‰°á‰µ áŒ¥áˆ«á‰µ á‰µáŠ•á‰ á‹«:** áŒ¥áˆ¬ á‹ˆá‰°á‰µ áˆ‹á‹­ á‹«áˆ‰ áˆ˜áˆ¨áŒƒá‹á‰½áŠ• á‰ áˆ˜áŒ á‰€áˆ á‹¨áˆ˜á‰ áˆ‹áˆ¸á‰µ áˆµáŒ‹á‰±áŠ• á‹­á‰°áŠ•á‰¥á‹©á¢
    - **á‹¨áˆ›á‹³á‰ áˆªá‹« áˆáŠ­áˆ¨ áˆ€áˆ³á‰¥:** áˆˆáŠ áˆáˆ­á‹ áŠ¥áŠ“ áˆˆáˆ°á‰¥áˆá‹ áŠ á‹­áŠá‰µ á‰°áˆµáˆ›áˆš á‹¨áˆ†áŠá‹áŠ• áˆ›á‹³á‰ áˆªá‹« á‹­á‹ˆá‰á¢
    - **á‹¨áˆ°á‰¥áˆ áˆáˆ­á‰µ á‰µáŠ•á‰ á‹«:** á‹¨á‰°áˆˆá‹«á‹© áŒá‰¥á‹“á‰¶á‰½áŠ• áˆ˜áˆ áˆ¨á‰µ á‰ áˆ›á‹µáˆ¨áŒ á‹¨áˆšáŒ á‰ á‰€á‹áŠ• áˆáˆ­á‰µ á‹­áŒˆáˆá‰±á¢
    - **á‹¨áŒá‰¥áˆ­áŠ“ áŠ áˆ›áŠ«áˆª (AI Chatbot):** áˆµáˆˆ áŒá‰¥áˆ­áŠ“ áŠ¥áŠ“ áˆáŒá‰¥ áŠáŠ­ áŒ‰á‹³á‹®á‰½ á‰ áŠ áˆ›áˆ­áŠ› áŒ¥á‹«á‰„á‹á‰½áŠ• á‹­áŒ á‹­á‰áŠ“ áˆ˜áˆáˆµ á‹«áŒáŠ™á¢
    - **á‹¨áŒá‰¥áˆ­áŠ“ áŠ¥á‰…á‹µ áŠ áˆµáˆ˜áˆ³á‹­:** á‹¨á‰°áˆˆá‹«á‹© á‹¨áŒá‰¥áˆ­áŠ“ á‹•á‰…á‹¶á‰½áŠ• á‰ áˆ›áˆµáˆ˜áˆ°áˆ á‹¨á‰°áˆ»áˆˆá‹áŠ• áˆáˆ­áŒ« áŠ¥áŠ•á‹²á‹«á‹°áˆ­áŒ‰ á‹«áŒá‹›áˆá¢

    á‹­áˆ… á•áˆ®áŒ€áŠ­á‰µ á‹¨á‰°á‹˜áŒ‹áŒ€á‹ á‹¨áŒá‰¥áˆ­áŠ“á‹áŠ• á‹˜áˆ­á á‰ á‰´áŠ­áŠ–áˆáŒ‚ áˆˆáˆ›áŒˆá‹ áŠá‹á¢
    """)
    st.image(logo_path if os.path.exists(logo_path) else "https://streamlit.io/images/brand/streamlit-logo-secondary-colormark-darktext.png", width=200)
else:
    app_function = app_options_main.get(st.session_state.main_selected_app_name)
    if app_function:
        app_function()
    else:
        st.error("á‹¨áˆ›á‹­á‰³á‹ˆá‰… áˆáˆ­áŒ«á¢ áŠ¥á‰£áŠ­á‹ áŠ¥áŠ•á‹°áŒˆáŠ“ á‹­áˆáŠ­áˆ©á¢")

st.sidebar.markdown("---")
st.sidebar.info("Â© 2024 á‹˜áˆ˜áŠ“á‹Š á‹¨áŒá‰¥áˆ­áŠ“ áˆ˜áá‰µáˆ„á‹á‰½")